{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.feature_extractor import DenseNetFE\n",
    "from model.transformer import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:3' if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# import skimage\n",
    "# from matplotlib import cm\n",
    "# import numpy as np\n",
    "from data import get_data_loader, get_vocab, SOS_CHAR, EOS_CHAR, PAD_CHAR\n",
    "from torchvision import transforms\n",
    "from utils import ScaleImageByHeight\n",
    "\n",
    "from inference_tf import inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CKPT = './runs/09-02-2020_00-10-39_tf_encoder_8_1_decoder_10_1_both_8/weights/BEST_weights.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device = cuda:3\n",
      "Load weight from ./runs/09-02-2020_00-10-39_tf_encoder_8_1_decoder_10_1_both_8/weights/BEST_weights.pt\n",
      "> /home/aioz-interns-1/working-dir/loi/model/transformer.py(87)greedy()\n",
      "-> for t in range(max_length):\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/aioz-interns-1/working-dir/loi/model/transformer.py(88)greedy()\n",
      "-> output, weight = self.decoder.forward(predicts, image_features)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/aioz-interns-1/working-dir/loi/model/transformer.py(89)greedy()\n",
      "-> output = self.character_distribution(output)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/aioz-interns-1/working-dir/loi/model/transformer.py(90)greedy()\n",
      "-> output = F.softmax(output, -1)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/aioz-interns-1/working-dir/loi/model/transformer.py(91)greedy()\n",
      "-> index = output.topk(1, -1)[1]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  output.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 150])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/aioz-interns-1/working-dir/loi/model/transformer.py(92)greedy()\n",
      "-> output = torch.zeros_like(output)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  index.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 1])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 57],\n",
      "         [ 25],\n",
      "         [ 32],\n",
      "         [ 51],\n",
      "         [ 57],\n",
      "         [ 32],\n",
      "         [ 24],\n",
      "         [ 32],\n",
      "         [ 49],\n",
      "         [ 40],\n",
      "         [ 66],\n",
      "         [ 44],\n",
      "         [ 51],\n",
      "         [ 49],\n",
      "         [ 26],\n",
      "         [ 32],\n",
      "         [ 44],\n",
      "         [ 80],\n",
      "         [ 34],\n",
      "         [ 32],\n",
      "         [ 51],\n",
      "         [ 14],\n",
      "         [ 32],\n",
      "         [ 56],\n",
      "         [ 24],\n",
      "         [ 16],\n",
      "         [ 16],\n",
      "         [106],\n",
      "         [ 60],\n",
      "         [ 49],\n",
      "         [136],\n",
      "         [  1]]], device='cuda:3')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  index.squeeze()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 57,  25,  32,  51,  57,  32,  24,  32,  49,  40,  66,  44,  51,  49,\n",
      "         26,  32,  44,  80,  34,  32,  51,  14,  32,  56,  24,  16,  16, 106,\n",
      "         60,  49, 136,   1], device='cuda:3')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  index.squeeze(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 57,  25,  32,  51,  57,  32,  24,  32,  49,  40,  66,  44,  51,  49,\n",
      "          26,  32,  44,  80,  34,  32,  51,  14,  32,  56,  24,  16,  16, 106,\n",
      "          60,  49, 136,   1]], device='cuda:3')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/aioz-interns-1/working-dir/loi/model/transformer.py(93)greedy()\n",
      "-> output.scatter_(-1, index, 1)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:3')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  output.max()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:3')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  output.min()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:3')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  output.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 150])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  index.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 1])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/aioz-interns-1/working-dir/loi/model/transformer.py(94)greedy()\n",
      "-> predicts = torch.cat([predicts, output], dim=0)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/aioz-interns-1/working-dir/loi/model/transformer.py(95)greedy()\n",
      "-> weights.append(weight)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  predicts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.]]], device='cuda:3')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  predicts.transpose(0,1).topk(1, -1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 12],\n",
      "         [ 57]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 25]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 32]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 51]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 57]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 32]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 24]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 32]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 49]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 40]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 66]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 44]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 51]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 49]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 26]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 32]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 44]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 80]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 34]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 32]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 51]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 14]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 32]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 56]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 24]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 16]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 16]],\n",
      "\n",
      "        [[ 12],\n",
      "         [106]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 60]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 49]],\n",
      "\n",
      "        [[ 12],\n",
      "         [136]],\n",
      "\n",
      "        [[ 12],\n",
      "         [  1]]], device='cuda:3')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/aioz-interns-1/working-dir/loi/model/transformer.py(87)greedy()\n",
      "-> for t in range(max_length):\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/aioz-interns-1/working-dir/loi/model/transformer.py(88)greedy()\n",
      "-> output, weight = self.decoder.forward(predicts, image_features)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/aioz-interns-1/working-dir/loi/model/transformer.py(89)greedy()\n",
      "-> output = self.character_distribution(output)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/aioz-interns-1/working-dir/loi/model/transformer.py(90)greedy()\n",
      "-> output = F.softmax(output, -1)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/aioz-interns-1/working-dir/loi/model/transformer.py(91)greedy()\n",
      "-> index = output.topk(1, -1)[1]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/aioz-interns-1/working-dir/loi/model/transformer.py(92)greedy()\n",
      "-> output = torch.zeros_like(output)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/aioz-interns-1/working-dir/loi/model/transformer.py(93)greedy()\n",
      "-> output.scatter_(-1, index, 1)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/aioz-interns-1/working-dir/loi/model/transformer.py(94)greedy()\n",
      "-> predicts = torch.cat([predicts, output], dim=0)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/aioz-interns-1/working-dir/loi/model/transformer.py(95)greedy()\n",
      "-> weights.append(weight)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  predicts.transpose(0,1).topk(1,-1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 12],\n",
      "         [ 57],\n",
      "         [ 57]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 25],\n",
      "         [ 25]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 32],\n",
      "         [ 32]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 51],\n",
      "         [ 51]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 57],\n",
      "         [ 57]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 32],\n",
      "         [ 32]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 24],\n",
      "         [ 24]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 32],\n",
      "         [ 32]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 49],\n",
      "         [ 49]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 40],\n",
      "         [ 40]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 66],\n",
      "         [ 66]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 44],\n",
      "         [ 44]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 51],\n",
      "         [ 51]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 49],\n",
      "         [ 49]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 26],\n",
      "         [ 26]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 32],\n",
      "         [ 32]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 44],\n",
      "         [ 44]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 80],\n",
      "         [ 80]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 34],\n",
      "         [ 34]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 32],\n",
      "         [ 32]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 51],\n",
      "         [ 51]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 14],\n",
      "         [ 14]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 32],\n",
      "         [ 32]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 56],\n",
      "         [  3]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 24],\n",
      "         [ 24]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 16],\n",
      "         [ 16]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 16],\n",
      "         [ 16]],\n",
      "\n",
      "        [[ 12],\n",
      "         [106],\n",
      "         [106]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 60],\n",
      "         [ 60]],\n",
      "\n",
      "        [[ 12],\n",
      "         [ 49],\n",
      "         [ 49]],\n",
      "\n",
      "        [[ 12],\n",
      "         [136],\n",
      "         [136]],\n",
      "\n",
      "        [[ 12],\n",
      "         [  1],\n",
      "         [  1]]], device='cuda:3')\n",
      "--KeyboardInterrupt--\n",
      "--KeyboardInterrupt--\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-faab766fc4cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/working-dir/loi/inference_tf.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(model, batch, vocab, device)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mtargets_onehot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets_onehot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgreedy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_onehot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# ignore <start>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/working-dir/loi/model/transformer.py\u001b[0m in \u001b[0;36mgreedy\u001b[0;34m(self, images, start_input, output_weight, max_length)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mPositionalEncoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/working-dir/loi/model/transformer.py\u001b[0m in \u001b[0;36mgreedy\u001b[0;34m(self, images, start_input, output_weight, max_length)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mPositionalEncoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cv/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cv/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('Device = {}'.format(device))\n",
    "print('Load weight from {}'.format(CKPT))\n",
    "checkpoint = torch.load(CKPT, map_location=device)\n",
    "config = checkpoint['config']\n",
    "\n",
    "cnn = DenseNetFE(config['depth'],\n",
    "                 config['n_blocks'],\n",
    "                 config['growth_rate'])\n",
    "\n",
    "vocab = get_vocab(config['dataset'])\n",
    "model = Transformer(cnn, vocab.vocab_size, config['attn_size'],\n",
    "                    config['encoder_nhead'], config['decoder_nhead'], config['both_nhead'],\n",
    "                    config['encoder_nlayers'], config['decoder_nlayers'])\n",
    "model.to(device)\n",
    "\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Grayscale(3),\n",
    "    ScaleImageByHeight(config['scale_height']),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_loader = get_data_loader(config['dataset'], 'test', config['batch_size'],\n",
    "                              test_transform, vocab)\n",
    "\n",
    "model.eval()\n",
    "batch = next(iter(test_loader))\n",
    "with torch.no_grad():\n",
    "    inference(model, batch, vocab, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = 1\n",
    "sample_image, sample_predict, sample_weigth = imgs[sample_index], predicts_str[sample_index], weights[:, [sample_index]]\n",
    "fig, axeses = plt.subplots(len(sample_predict), figsize=(15,15), sharex=True, sharey=True)\n",
    "\n",
    "for i, axes in enumerate(axeses.ravel()):\n",
    "    weight = weights[i].reshape(-1, config['batch_size'], img_rows // 16, img_cols // 16) # 16 is factor that DenseNet reduce the original image size\n",
    "    weight_numpy = weight.cpu().numpy()[:,sample_index,:].squeeze()\n",
    "    weight_image = skimage.transform.resize(weight_numpy, (img_rows, img_cols))\n",
    "    \n",
    "    img = sample_image.squeeze().permute(1,2,0).cpu().numpy()[:,:,0]\n",
    "    \n",
    "    alpha = 0.5\n",
    "    blend = img * alpha + weight_image * (1-alpha)\n",
    "    \n",
    "    axes.set_title(sample_predict[i])\n",
    "    axes.imshow(blend, cmap='spring')\n",
    "plt.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calc CER, WER on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import editdistance as ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_test = open('./log_test.txt', 'w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 - sample 25: \"['u', 'n', '<end>']\"/\"['O', 'n', '<end>']\"\n",
      "Batch 0 - sample 26: \"['u', 'n', '<end>']\"/\"['O', 'n', '<end>']\"\n",
      "Batch 2 - sample 31: \"['u', 'n', '<end>']\"/\"['O', 'n', '<end>']\"\n",
      "Batch 8 - sample 31: \"['u', 'n', '<end>']\"/\"['O', 'n', '<end>']\"\n",
      "Batch 9 - sample 13: \"['s', 's', 'n', '<end>']\"/\"['s', 'ẵ', 'n', '<end>']\"\n",
      "Batch 15 - sample 27: \"['u', 'n', '<end>']\"/\"['O', 'n', '<end>']\"\n",
      "Batch 16 - sample 26: \"['u', 'n', '<end>']\"/\"['O', 'n', '<end>']\"\n",
      "Batch 17 - sample 30: \"['u', 'n', '<end>']\"/\"['O', 'n', '<end>']\"\n",
      "Batch 24 - sample 30: \"['u', 'n', '<end>']\"/\"['O', 'n', '<end>']\"\n",
      "Batch 28 - sample 21: \"['s', 's', 'n', '<end>']\"/\"['s', 'ẵ', 'n', '<end>']\"\n",
      "Batch 29 - sample 25: \"['u', 'n', '<end>']\"/\"['O', 'n', '<end>']\"\n",
      "Batch 31 - sample 27: \"['M', 'M', '<end>']\"/\"['M', 'ỹ', '<end>']\"\n",
      "Batch 39 - sample 22: \"['u', 'n', '<end>']\"/\"['O', 'n', '<end>']\"\n",
      "Batch 39 - sample 28: \"['k', 'k', '<end>']\"/\"['k', 'ỳ', '<end>']\"\n",
      "Batch 39 - sample 31: \"['y', 'n', '<end>']\"/\"['Â', 'n', '<end>']\"\n",
      "Batch 40 - sample 4: \"['A', 'A', 'D', 'S', '<end>']\"/\"['A', 'I', 'D', 'S', '<end>']\"\n",
      "Batch 40 - sample 22: \"['ệ', 'y', '<end>']\"/\"['Ủ', 'y', '<end>']\"\n",
      "Batch 41 - sample 19: \"['H', 'H', 'V', '<end>']\"/\"['H', 'I', 'V', '<end>']\"\n",
      "Batch 42 - sample 3: \"['N', 'N', 'n', 'g', '<end>']\"/\"['N', 'ẵ', 'n', 'g', '<end>']\"\n",
      "Batch 42 - sample 23: \"['H', 'H', 'V', '<end>']\"/\"['H', 'I', 'V', '<end>']\"\n",
      "Batch 42 - sample 31: \"['P', '<end>']\"/\"['Ở', '<end>']\"\n",
      "Batch 44 - sample 8: \"['A', 'A', 'D', 'S', '<end>']\"/\"['A', 'I', 'D', 'S', '<end>']\"\n",
      "Batch 44 - sample 9: \"['N', 'N', 'n', 'g', '<end>']\"/\"['N', 'ẵ', 'n', 'g', '<end>']\"\n",
      "Batch 46 - sample 11: \"['A', 'A', 'D', 'S', '<end>']\"/\"['A', 'I', 'D', 'S', '<end>']\"\n",
      "Batch 46 - sample 22: \"['k', 'k', '<end>']\"/\"['k', 'ỳ', '<end>']\"\n",
      "Batch 48 - sample 14: \"['H', 'H', 'V', '<end>']\"/\"['H', 'I', 'V', '<end>']\"\n",
      "Batch 50 - sample 15: \"['H', 'H', 'V', '<end>']\"/\"['H', 'I', 'V', '<end>']\"\n",
      "Batch 50 - sample 31: \"['P', '<end>']\"/\"['Ở', '<end>']\"\n",
      "Batch 52 - sample 24: \"['H', 'H', 'V', '<end>']\"/\"['H', 'I', 'V', '<end>']\"\n",
      "Batch 52 - sample 28: \"['k', 'k', '<end>']\"/\"['k', 'ỳ', '<end>']\"\n",
      "Batch 54 - sample 17: \"['H', 'H', 'V', '<end>']\"/\"['H', 'I', 'V', '<end>']\"\n",
      "Batch 55 - sample 14: \"['H', 'H', 'V', '<end>']\"/\"['H', 'I', 'V', '<end>']\"\n",
      "Batch 55 - sample 29: \"['y', 'n', '<end>']\"/\"['Â', 'n', '<end>']\"\n",
      "Batch 56 - sample 11: \"['A', 'A', 'D', 'S', '<end>']\"/\"['A', 'I', 'D', 'S', '<end>']\"\n",
      "Batch 56 - sample 13: \"['2', '0', '0', '0', '<end>']\"/\"['2', '0', '0', '5', '<end>']\"\n",
      "Batch 56 - sample 15: \"['H', 'H', 'V', '<end>']\"/\"['H', 'I', 'V', '<end>']\"\n",
      "Batch 56 - sample 27: \"['k', 'k', '<end>']\"/\"['k', 'ỳ', '<end>']\"\n",
      "Batch 56 - sample 31: \"['ệ', 'y', '<end>']\"/\"['Ủ', 'y', '<end>']\"\n",
      "Batch 57 - sample 15: \"['H', 'H', 'V', '<end>']\"/\"['H', 'I', 'V', '<end>']\"\n",
      "Batch 57 - sample 21: \"['H', 'H', 'V', '<end>']\"/\"['H', 'I', 'V', '<end>']\"\n",
      "Batch 59 - sample 6: \"['N', 'N', 'n', 'g', '<end>']\"/\"['N', 'ẵ', 'n', 'g', '<end>']\"\n",
      "Batch 64 - sample 6: \"['A', 'A', 'D', 'S', '<end>']\"/\"['A', 'I', 'D', 'S', '<end>']\"\n",
      "Batch 64 - sample 9: \"['H', 'H', 'V', '<end>']\"/\"['H', 'I', 'V', '<end>']\"\n",
      "Batch 65 - sample 17: \"['H', 'H', 'V', '<end>']\"/\"['H', 'I', 'V', '<end>']\"\n",
      "Batch 68 - sample 12: \"['H', 'H', 'V', '<end>']\"/\"['H', 'I', 'V', '<end>']\"\n",
      "Batch 70 - sample 13: \"['N', 'N', 'n', 'g', '<end>']\"/\"['N', 'ẵ', 'n', 'g', '<end>']\"\n",
      "Batch 70 - sample 23: \"['H', 'H', 'V', '<end>']\"/\"['H', 'I', 'V', '<end>']\"\n",
      "Batch 71 - sample 11: \"['H', 'H', 'V', '<end>']\"/\"['H', 'I', 'V', '<end>']\"\n",
      "Batch 72 - sample 14: \"['H', 'H', 'V', '<end>']\"/\"['H', 'I', 'V', '<end>']\"\n",
      "Batch 72 - sample 16: \"['H', 'H', 'V', '<end>']\"/\"['H', 'I', 'V', '<end>']\"\n",
      "Batch 73 - sample 17: \"['H', 'H', 'V', '<end>']\"/\"['H', 'I', 'V', '<end>']\"\n",
      "Batch 75 - sample 14: \"['H', 'H', 'V', '<end>']\"/\"['H', 'I', 'V', '<end>']\"\n",
      "Batch 78 - sample 3: \"['N', 'N', 'n', 'g', '<end>']\"/\"['N', 'ẵ', 'n', 'g', '<end>']\"\n",
      "Batch 80 - sample 28: \"['k', 'k', '<end>']\"/\"['k', 'ỳ', '<end>']\"\n",
      "Batch 81 - sample 22: \"['H', 'H', 'V', '<end>']\"/\"['H', 'I', 'V', '<end>']\"\n",
      "Batch 86 - sample 31: \"['P', '<end>']\"/\"['Ở', '<end>']\"\n",
      "Batch 87 - sample 29: \"['H', 'H', 'V', '<end>']\"/\"['H', 'I', 'V', '<end>']\"\n",
      "Batch 88 - sample 5: \"['N', 'N', 'n', 'g', '<end>']\"/\"['N', 'ẵ', 'n', 'g', '<end>']\"\n",
      "Batch 89 - sample 13: \"['A', 'A', 'D', 'S', '<end>']\"/\"['A', 'I', 'D', 'S', '<end>']\"\n",
      "Batch 89 - sample 23: \"['H', 'H', 'V', '<end>']\"/\"['H', 'I', 'V', '<end>']\"\n",
      "Batch 90 - sample 21: \"['H', 'H', 'V', '<end>']\"/\"['H', 'I', 'V', '<end>']\"\n",
      "Batch 91 - sample 10: \"['A', 'A', 'D', 'S', '<end>']\"/\"['A', 'I', 'D', 'S', '<end>']\"\n",
      "Batch 92 - sample 18: \"['H', 'H', 'V', '<end>']\"/\"['H', 'I', 'V', '<end>']\"\n",
      "Batch 92 - sample 19: \"['H', 'H', 'V', '<end>']\"/\"['H', 'I', 'V', '<end>']\"\n",
      "Batch 93 - sample 27: \"['k', 'k', '<end>']\"/\"['k', 'ỳ', '<end>']\"\n",
      "Batch 143 - sample 25: \"['k', 'k', '<end>']\"/\"['k', 'ỳ', '<end>']\"\n",
      "Batch 161 - sample 2: \"['u', 'a', 'n', 'h', '<end>']\"/\"['O', 'a', 'n', 'h', '<end>']\"\n",
      "Batch 161 - sample 8: \"['u', 'a', 'n', 'h', '<end>']\"/\"['O', 'a', 'n', 'h', '<end>']\"\n",
      "Batch 167 - sample 12: \"['u', 'a', 'n', 'h', '<end>']\"/\"['O', 'a', 'n', 'h', '<end>']\"\n",
      "Batch 168 - sample 14: \"['u', 'a', 'n', 'h', '<end>']\"/\"['O', 'a', 'n', 'h', '<end>']\"\n",
      "Batch 169 - sample 25: \"['k', 'k', '<end>']\"/\"['k', 'ỹ', '<end>']\"\n",
      "Batch 170 - sample 4: \"['u', 'a', 'n', 'h', '<end>']\"/\"['O', 'a', 'n', 'h', '<end>']\"\n",
      "Batch 172 - sample 5: \"['u', 'a', 'n', 'h', '<end>']\"/\"['O', 'a', 'n', 'h', '<end>']\"\n",
      "Batch 172 - sample 8: \"['u', 'a', 'n', 'h', '<end>']\"/\"['O', 'a', 'n', 'h', '<end>']\"\n",
      "Batch 174 - sample 6: \"['u', 'a', 'n', 'h', '<end>']\"/\"['O', 'a', 'n', 'h', '<end>']\"\n",
      "Batch 175 - sample 10: \"['u', 'a', 'n', 'h', '<end>']\"/\"['O', 'a', 'n', 'h', '<end>']\"\n",
      "Batch 176 - sample 4: \"['u', 'a', 'n', 'h', '<end>']\"/\"['O', 'a', 'n', 'h', '<end>']\"\n",
      "Batch 188 - sample 29: \"['V', 'V', '<end>']\"/\"['V', 'ỹ', '<end>']\"\n",
      "Batch 193 - sample 18: \"['s', 's', 'n', '<end>']\"/\"['s', 'ẵ', 'n', '<end>']\"\n",
      "Batch 195 - sample 26: \"['M', 'M', '<end>']\"/\"['M', 'ỹ', '<end>']\"\n",
      "Batch 197 - sample 17: \"['<end>']\"/\"['Á', 'n', 'h', '<end>']\"\n",
      "Batch 205 - sample 8: \"['P', 'm', 'C', 'A', '<end>']\"/\"['J', 'I', 'C', 'A', '<end>']\"\n",
      "Batch 207 - sample 24: \"['M', 'M', '<end>']\"/\"['M', 'ỹ', '<end>']\"\n",
      "Batch 208 - sample 26: \"['M', 'M', '<end>']\"/\"['M', 'ỹ', '<end>']\"\n",
      "Batch 232 - sample 29: \"['5', '5', '<end>']\"/\"['5', '8', '<end>']\"\n",
      "Batch 234 - sample 27: \"['â', '5', '<end>']\"/\"['E', '5', '<end>']\"\n",
      "Batch 238 - sample 0: \"['S', 'a', 'n', 'o', 'o', 'i', '<end>']\"/\"['S', 'a', 'n', 'o', 'f', 'i', '<end>']\"\n",
      "Batch 239 - sample 1: \"['S', 'a', 'n', 'o', 'o', 'i', '<end>']\"/\"['S', 'a', 'n', 'o', 'f', 'i', '<end>']\"\n",
      "Batch 243 - sample 29: \"['s', 'B', '<end>']\"/\"['W', 'B', '<end>']\"\n",
      "Batch 244 - sample 21: \"['s', 'B', '<end>']\"/\"['W', 'B', '<end>']\"\n",
      "Batch 244 - sample 26: \"['s', 'B', '<end>']\"/\"['W', 'B', '<end>']\"\n",
      "Batch 251 - sample 9: \"['A', 'A', 'D', 'S', '<end>']\"/\"['A', 'I', 'D', 'S', '<end>']\"\n",
      "Batch 257 - sample 24: \"['2', '2', '2', '<end>']\"/\"['2', '2', '9', '<end>']\"\n",
      "Batch 259 - sample 17: \"['H', 'H', 'V', '<end>']\"/\"['H', 'I', 'V', '<end>']\"\n",
      "Batch 260 - sample 21: \"['H', 'H', 'V', '<end>']\"/\"['H', 'I', 'V', '<end>']\"\n",
      "Batch 267 - sample 0: \"['S', 'a', 'n', 'o', 'o', 'i', '<end>']\"/\"['S', 'a', 'n', 'o', 'f', 'i', '<end>']\"\n",
      "Batch 268 - sample 1: \"['S', 'a', 'n', 'o', 'o', 'i', '<end>']\"/\"['S', 'a', 'n', 'o', 'f', 'i', '<end>']\"\n",
      "Batch 279 - sample 27: \"['5', '5', '<end>']\"/\"['5', '8', '<end>']\"\n",
      "Batch 282 - sample 29: \"['K', 'K', '<end>']\"/\"['K', 'ỳ', '<end>']\"\n",
      "Batch 323 - sample 29: \"['k', '<end>']\"/\"['Ồ', '<end>']\"\n",
      "Batch 332 - sample 31: \"['k', 'b', '<end>']\"/\"['k', 'ỷ', '<end>']\"\n",
      "Batch 336 - sample 11: \"['s', 's', 'n', '<end>']\"/\"['s', 'ẵ', 'n', '<end>']\"\n",
      "Batch 347 - sample 27: \"['k', 'ắ', '<end>']\"/\"['k', 'ỷ', '<end>']\"\n",
      "Batch 348 - sample 30: \"['<end>']\"/\"['Á', 'i', '<end>']\"\n",
      "Batch 363 - sample 28: \"['k', 'ắ', '<end>']\"/\"['k', 'ỷ', '<end>']\"\n",
      "Batch 369 - sample 31: \"['P', '<end>']\"/\"['Ở', '<end>']\"\n",
      "Batch 378 - sample 28: \"['k', 'b', '<end>']\"/\"['k', 'ỷ', '<end>']\"\n",
      "Batch 380 - sample 26: \"['<end>']\"/\"['Á', 'i', '<end>']\"\n",
      "Batch 417 - sample 4: \"['K', 'K', 'a', 'n', 'g', '<end>']\"/\"['K', 'j', 'a', 'n', 'g', '<end>']\"\n",
      "Batch 428 - sample 0: \"['S', 'a', 'n', 'o', 'o', 'i', '<end>']\"/\"['S', 'a', 'n', 'o', 'f', 'i', '<end>']\"\n",
      "Batch 429 - sample 1: \"['S', 'a', 'n', 'o', 'o', 'i', '<end>']\"/\"['S', 'a', 'n', 'o', 'f', 'i', '<end>']\"\n",
      "Batch 444 - sample 31: \"['P', '<end>']\"/\"['Ở', '<end>']\"\n",
      "Batch 469 - sample 27: \"['k', 'k', '<end>']\"/\"['k', 'ỳ', '<end>']\"\n",
      "Batch 470 - sample 0: \"['i', 'g', 'n', 'a', 'r', 'a', 'a', 'a', '<end>']\"/\"['i', 'g', 'n', 'a', 'r', 'a', 'j', 'a', '<end>']\"\n",
      "Batch 470 - sample 28: \"['k', 'b', '<end>']\"/\"['k', 'ỷ', '<end>']\"\n",
      "Batch 475 - sample 27: \"['k', 'ắ', '<end>']\"/\"['k', 'ỷ', '<end>']\"\n",
      "Batch 476 - sample 31: \"['<end>']\"/\"['Á', 'i', '<end>']\"\n",
      "Batch 488 - sample 1: \"['S', 'a', 'n', 'o', 'o', 'i', '<end>']\"/\"['S', 'a', 'n', 'o', 'f', 'i', '<end>']\"\n",
      "Batch 489 - sample 1: \"['S', 'a', 'n', 'o', 'o', 'i', '<end>']\"/\"['S', 'a', 'n', 'o', 'f', 'i', '<end>']\"\n",
      "Batch 496 - sample 25: \"['s', 's', 'n', '<end>']\"/\"['s', 'ẵ', 'n', '<end>']\"\n",
      "Batch 506 - sample 9: \"['s', 's', 'n', '<end>']\"/\"['s', 'ẵ', 'n', '<end>']\"\n",
      "Batch 512 - sample 0: \"['S', 'a', 'n', 'o', 'o', 'i', '<end>']\"/\"['S', 'a', 'n', 'o', 'f', 'i', '<end>']\"\n",
      "Batch 513 - sample 1: \"['S', 'a', 'n', 'o', 'o', 'i', '<end>']\"/\"['S', 'a', 'n', 'o', 'f', 'i', '<end>']\"\n",
      "Batch 520 - sample 27: \"['k', 'b', '<end>']\"/\"['k', 'ỷ', '<end>']\"\n",
      "Batch 523 - sample 23: \"['k', 'b', '<end>']\"/\"['k', 'ỷ', '<end>']\"\n",
      "Batch 523 - sample 24: \"['k', 'b', '<end>']\"/\"['k', 'ỷ', '<end>']\"\n",
      "Batch 523 - sample 27: \"['k', 'b', '<end>']\"/\"['k', 'ỷ', '<end>']\"\n",
      "Batch 527 - sample 12: \"['2', '0', '0', '0', '<end>']\"/\"['2', '0', '0', '5', '<end>']\"\n",
      "Batch 572 - sample 30: \"['â', '5', '<end>']\"/\"['E', '5', '<end>']\"\n",
      "Batch 579 - sample 26: \"['k', 'k', '<end>']\"/\"['k', 'ỳ', '<end>']\"\n",
      "Batch 580 - sample 0: \"['i', 'g', 'n', 'a', 'r', 'a', 'a', 'a', '<end>']\"/\"['i', 'g', 'n', 'a', 'r', 'a', 'j', 'a', '<end>']\"\n",
      "Batch 580 - sample 28: \"['k', 'ắ', '<end>']\"/\"['k', 'ỷ', '<end>']\"\n",
      "Batch 586 - sample 26: \"['k', 'k', '<end>']\"/\"['k', 'ỳ', '<end>']\"\n",
      "Batch 587 - sample 0: \"['i', 'g', 'n', 'a', 'r', 'a', 'a', 'a', '<end>']\"/\"['i', 'g', 'n', 'a', 'r', 'a', 'j', 'a', '<end>']\"\n",
      "Batch 587 - sample 28: \"['k', 'ắ', '<end>']\"/\"['k', 'ỷ', '<end>']\"\n",
      "Batch 594 - sample 10: \"['s', 's', 'n', '<end>']\"/\"['s', 'ẵ', 'n', '<end>']\"\n",
      "Batch 600 - sample 31: \"['P', '<end>']\"/\"['Ở', '<end>']\"\n",
      "Batch 607 - sample 31: \"['P', '<end>']\"/\"['Ở', '<end>']\"\n",
      "Batch 609 - sample 30: \"['ậ', 'n', '<end>']\"/\"['Ă', 'n', '<end>']\"\n",
      "Batch 631 - sample 10: \"['s', 's', 'n', '<end>']\"/\"['s', 'ẵ', 'n', '<end>']\"\n",
      "Batch 637 - sample 0: \"['S', 'a', 'n', 'o', 'o', 'i', '<end>']\"/\"['S', 'a', 'n', 'o', 'f', 'i', '<end>']\"\n",
      "Batch 638 - sample 1: \"['S', 'a', 'n', 'o', 'o', 'i', '<end>']\"/\"['S', 'a', 'n', 'o', 'f', 'i', '<end>']\"\n",
      "Batch 645 - sample 17: \"['P', 'T', 'C', 'A', '<end>']\"/\"['J', 'I', 'C', 'A', '<end>']\"\n",
      "Batch 647 - sample 31: \"['M', 'M', '<end>']\"/\"['M', 'ỹ', '<end>']\"\n",
      "Batch 648 - sample 30: \"['M', 'M', '<end>']\"/\"['M', 'ỹ', '<end>']\"\n",
      "Batch 670 - sample 27: \"['5', '5', '<end>']\"/\"['5', '8', '<end>']\"\n",
      "Batch 672 - sample 17: \"['s', 's', 'n', '<end>']\"/\"['s', 'ẵ', 'n', '<end>']\"\n",
      "Batch 689 - sample 12: \"['s', 's', 'n', '<end>']\"/\"['s', 'ẵ', 'n', '<end>']\"\n",
      "Batch 698 - sample 18: \"['P', 'T', 'C', 'A', '<end>']\"/\"['J', 'I', 'C', 'A', '<end>']\"\n",
      "Batch 701 - sample 23: \"['M', 'M', '<end>']\"/\"['M', 'ỹ', '<end>']\"\n",
      "Batch 702 - sample 25: \"['M', 'M', '<end>']\"/\"['M', 'ỹ', '<end>']\"\n",
      "Batch 704 - sample 28: \"['k', 'k', '<end>']\"/\"['k', 'ỳ', '<end>']\"\n",
      "Batch 705 - sample 31: \"['k', 'b', '<end>']\"/\"['k', 'ỷ', '<end>']\"\n",
      "Batch 706 - sample 0: \"['i', 'g', 'n', 'a', 'r', 'a', 'a', 'a', '<end>']\"/\"['i', 'g', 'n', 'a', 'r', 'a', 'j', 'a', '<end>']\"\n",
      "Batch 757 - sample 31: \"['k', 'k', '<end>']\"/\"['k', 'ỹ', '<end>']\"\n",
      "Batch 777 - sample 27: \"['k', 'b', '<end>']\"/\"['k', 'ỷ', '<end>']\"\n"
     ]
    }
   ],
   "source": [
    "total_characters = 0\n",
    "total_words = 0\n",
    "CE = 0\n",
    "WE = 0\n",
    "log_interval = 10\n",
    "\n",
    "# t = tqdm(test_loader)\n",
    "t = test_loader\n",
    "with torch.no_grad():\n",
    "    for i, (imgs, targets, targets_onehot, lengths) in enumerate(t):\n",
    "        print(f'[{i}]/[{len(t)}]', file=log_test)\n",
    "        log_test.flush()\n",
    "        batch_size = imgs.size(0)\n",
    "        \n",
    "        imgs = imgs.to(device)\n",
    "        img_features = encoder(imgs)\n",
    "        targets_onehot = targets_onehot[1:].to(device)\n",
    "        targets = targets[1:].to(device)\n",
    "        lengths = lengths - 1\n",
    "        outputs = decoder.forward(img_features, targets_onehot, targets, lengths, char2int[PAD_CHAR])\n",
    "        \n",
    "        _, index = outputs.topk(1, -1)\n",
    "        predicts = index.squeeze().transpose(0, 1) # [B, T]\n",
    "        predicts_str = []\n",
    "        for predict in predicts:\n",
    "            s = [int2char[x.item()] for x in predict]\n",
    "            try:\n",
    "                eos_index = s.index(EOS_CHAR) + 1\n",
    "            except ValueError:\n",
    "                eos_index = len(s)\n",
    "            predicts_str.append(s[:eos_index])\n",
    "\n",
    "        targets_str = []\n",
    "        for target in targets.transpose(0, 1).squeeze():\n",
    "            s = [int2char[x.item()] for x in target]\n",
    "            try:\n",
    "                eos_index = s.index(EOS_CHAR) + 1\n",
    "            except ValueError:\n",
    "                eos_index = len(s)\n",
    "            targets_str.append(s[:eos_index])\n",
    "        \n",
    "        assert len(predicts_str) == len(targets_str)\n",
    "        for j in range(len(predicts_str)):\n",
    "            CE += ed.distance(predicts_str[j], targets_str[j])\n",
    "        total_characters += lengths.sum().item()\n",
    "        \n",
    "        for j in range(len(predicts_str)):\n",
    "            if not np.array_equal(np.array(predicts_str[j]), np.array(targets_str[j])):\n",
    "                WE += 1\n",
    "                print(f'Batch {i} - sample {j}: \"{predicts_str[j]}\"/\"{targets_str[j]}\"')\n",
    "        total_words += len(predicts_str)\n",
    "        \n",
    "#         t.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "CER = CE / total_characters\n",
    "WER = WE / total_words\n",
    "print('CER', CER, file=log_test)\n",
    "print('WER', WER, file=log_test)\n",
    "log_test.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164 108614 0.0015099342626180786\n"
     ]
    }
   ],
   "source": [
    "print(CE, total_characters, CER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156 25115 0.0062114274338044995\n"
     ]
    }
   ],
   "source": [
    "print(WE, total_words, WER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
