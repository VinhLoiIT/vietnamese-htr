{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of gated_attention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdyIpXsB0yUE",
        "colab_type": "text"
      },
      "source": [
        "# Load dataset from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LcR8wysPjzOB",
        "outputId": "4418fc8a-0c77-49d7-80ad-725dd8125931",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S_zVf9zReBXA",
        "colab": {}
      },
      "source": [
        "!mkdir -p ./data/VNOnDB"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IDyCPQ16gb3v",
        "outputId": "5b6add74-f734-4fd3-e7ae-f58e95a31b37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "!unzip './drive/My Drive/VNOnDB/word_train.zip' -d ./data/VNOnDB >> log_extract.txt\n",
        "print('Extracted word_train.zip')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "replace ./data/VNOnDB/word_train/20140927_0017_6046_1_tg_4_4_1.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
            "N\n",
            "N\n",
            "Extracted word_train.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ApuJX1-AftE3",
        "outputId": "438a2862-dc33-44cd-c9e0-baea9ad294e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!unzip './drive/My Drive/VNOnDB/word_val.zip' -d ./data/VNOnDB >> log_extract.txt\n",
        "print('Extracted word_val.zip')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "replace ./data/VNOnDB/word_val/20151224_0141_7818_1_tg_0_0_0.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
            "Extracted word_val.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VogoOFvTfMg_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8940552b-aa37-4cae-cbb0-b3736dca366e"
      },
      "source": [
        "!unzip './drive/My Drive/VNOnDB/word_test.zip' -d ./data/VNOnDB >> log_extract.txt\n",
        "print('Extracted word_test.zip')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "replace ./data/VNOnDB/word_test/20151208_0146_7105_1_tg_0_0_0.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
            "Extracted word_test.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "etUi9fPsgp1x",
        "outputId": "f3f9231a-2768-4ef0-cdbf-492b5520ada0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!cp './drive/My Drive/VNOnDB/train_word.csv' ./data/VNOnDB/\n",
        "!cp './drive/My Drive/VNOnDB/test_word.csv' ./data/VNOnDB/\n",
        "!cp './drive/My Drive/VNOnDB/validation_word.csv' ./data/VNOnDB/\n",
        "print('Copied csv files')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copied csv files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p7be0t5-ch_X",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import AxesGrid\n",
        "import math\n",
        "\n",
        "import pdb\n",
        "\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5d4FUK_5ch_Z",
        "colab": {}
      },
      "source": [
        "import skimage.io as io\n",
        "from skimage.transform import rescale"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Uh_VdlXsch_c",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VHu8L5opch_e",
        "colab": {}
      },
      "source": [
        "def get_vietnamese_alphabets(is_include_space=False):\n",
        "    lower_vowels_with_dm = u'áàảãạắằẳãặâấầẩẫậíìỉĩịúùủũụưứừửữựéèẻẽẹêếềểễệóòỏõọơớờởỡợôốồổỗộyýỳỷỹỵ'\n",
        "    upper_vowels_with_dm = lower_vowels_with_dm.upper()\n",
        "    lower_without_dm = u'abcdefghijklmnopqrstuvwxyzđ'\n",
        "    upper_without_dm = lower_without_dm.upper()\n",
        "    digits = '1234567890'\n",
        "    \n",
        "    if is_include_space:\n",
        "        symbols = '?/*+-!,.\"\\':;#%&()[] ' # including space character ' ' is using for line recognition only \n",
        "    else:\n",
        "        symbols = '?/*+-!,.\"\\':;#%&()[]' # including space character ' ' is using for line recognition only\n",
        "    alphabets = lower_vowels_with_dm + lower_without_dm + upper_vowels_with_dm + upper_without_dm + digits + symbols\n",
        "    return alphabets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RmqkMiVXch_h",
        "colab": {}
      },
      "source": [
        "class LabelEncoderDecoder:\n",
        "    \"\"\"\n",
        "    Encode a string to one hot vectors and vice versa\n",
        "    \"\"\"\n",
        "    def __init__(self, alphabets=None, eos_char=None, is_include_space=False):\n",
        "        \n",
        "        self.alphabets = alphabets or get_vietnamese_alphabets(is_include_space)\n",
        "        self.eos_char = eos_char or '\\n'    \n",
        "        \n",
        "        self.alphabets = self.alphabets + self.eos_char\n",
        "        self.char_to_int = dict((c, i) for i, c in enumerate(self.alphabets))\n",
        "        self.int_to_char = dict((i, c) for i, c in enumerate(self.alphabets))\n",
        "\n",
        "    def encode(self, string):\n",
        "        \"\"\"\n",
        "        Encode a string to one hot vector using alphabets\n",
        "        \"\"\"\n",
        "        encoded_vectors = []\n",
        "        for char in string:\n",
        "            vector = [0]*len(self.alphabets)\n",
        "            vector[self.char_to_int[char]] = 1\n",
        "            encoded_vectors.append(vector)\n",
        "        return np.array(encoded_vectors, dtype=int)\n",
        "\n",
        "    def decode(self, vectors):\n",
        "        string = ''.join(self.int_to_char[np.argmax(vector)] for vector in vectors)\n",
        "        string = string.replace(self.eos_char, '')\n",
        "        return string\n",
        "    \n",
        "label_encoder_decoder = LabelEncoderDecoder(get_vietnamese_alphabets(is_include_space=False), eos_char='\\n', is_include_space=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EcCXnKVDch_i",
        "colab": {}
      },
      "source": [
        "# TODO: this is temporal for now, because line-level has less files than word-level, thus load faster.\n",
        "# img_train_folder = './data/VNOnDB/line_train/'\n",
        "# img_val_folder = './data/VNOnDB/line_val/'\n",
        "# img_test_folder = './data/VNOnDB/line_test/'\n",
        "train_folder = './data/VNOnDB/word_train/'\n",
        "val_folder = './data/VNOnDB/word_val/'\n",
        "test_folder = './data/VNOnDB/word_test/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SsgLLfz9ch_k",
        "colab": {}
      },
      "source": [
        "class VNOnDBDataset(Dataset):\n",
        "    def __init__(self, root_dir, dataframe, image_transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        \n",
        "        self.df = dataframe\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        image_path = os.path.join(self.root_dir, self.df['id'][idx]+'.png')\n",
        "        image = io.imread(image_path)\n",
        "        \n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        label = self.df['label'][idx]\n",
        "        label = label + label_encoder_decoder.eos_char\n",
        "        label = label_encoder_decoder.encode(label)\n",
        "            \n",
        "        return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yYixKHSGch_m",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    # transforms.Resize((320, 480)),\n",
        "#     transforms.Resize((8, 12)),\n",
        "    transforms.Grayscale(),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JwEeqrC4ch_o",
        "outputId": "7f6a4256-0680-4c81-a78c-dde478b422b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "# TEST\n",
        "mode = 'train'\n",
        "level = 'word'\n",
        "\n",
        "df = pd.read_csv(f'./data/VNOnDB/{mode}_{level}.csv', sep='\\t', index_col=0)\n",
        "print(len(df))\n",
        "dataset = VNOnDBDataset(f'./data/VNOnDB/{level}_{mode}', df, transform)\n",
        "\n",
        "X, y = dataset[803]\n",
        "# plt.rcParams['figure.figsize'] = (2,1)\n",
        "plt.imshow(torch.squeeze(X), cmap='gray')\n",
        "print(X.shape, y.shape)\n",
        "label_encoder_decoder.decode(y)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "66991\n",
            "torch.Size([1, 1168, 1406]) (5, 216)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'đáng'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT8AAAD8CAYAAAABraMFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XuUVXX9//HnWxAIUO4iwhgolKgk\nwmRgYqYg6ErQlpqXjL4/i9T0l5F901xmWT+X9cv8apnlLfGnaWWWLMsEvJWG5qAJKgOMCjqIgFy1\nALm8f3+cvaczwzAz5+zbubwea82acz5nn89+z559Xmfft7k7IiLVZq+sCxARyYLCT0SqksJPRKqS\nwk9EqpLCT0SqksJPRKpS6uFnZlPMbImZNZjZ5WmPX0QEwNI8zs/MOgFLgUlAI/A8cLa7v5paESIi\npL/kdxTQ4O6vu/sHwP3AtJRrEBGhc8rjGwy8lfe8EfhE/gBmNgOYAdCjR4+xhxxySHrViUjJW7Bg\nwbvuPiBqP2mHX7vc/VbgVoDa2lqvq6vLuCIRKSVmtiKOftJe7V0J1OQ9HxK0iYikKu3wex4YYWbD\nzKwLcBYwO+UaRETSXe119x1mdjHwKNAJuNPdX0mzBhERyGCbn7v/Gfhz2uMVEcmnMzxEpCop/ESk\nKin8RKQqKfxEpCop/ESkKin8RKQqKfxEpCop/ESkKin8pGqZGR/60IeyLkMyovCTqrZ169asS5CM\nKPyk6plZ1iVIBhR+UrUWLFiQdQmSIYWfVK0xY8Y0PdbSX/VR+FWw6667LusSREqWwq9CjRw5kiuu\nuCLrMspK//79sy5BUqTwq1D19fWAVufas3379qbH69aty7ASSZvCrwLt2rULgNGjR2dcSenr3Dl3\nPd80718tpUHhV4E6deoEwIsvvghor2ZHXHPNNYCWlKuJwq8K1NbWZl1Cybv66qtpaGjIugxJkcKv\nQmkJpnAHH3wwAB/+8IczrkTSoPCrUJs3b866hLL15ptvZl2CpEDhV6F69uyZdQllI3+zQLjj44UX\nXsiqHEmJwq/CXHDBBVmXUHaeeuqp3drGjh2bQSWSJoVfhfnlL3+ZdQllp3v37gA88MADAHzsYx/L\nshxJicJPJHDGGWcA8NJLL2VciaRB4VeBvvrVr2ZdQkXQHvPKpvCrQD/72c+yLqHszZ07N+sSJGEK\nPxF2P7Zv4sSJADz88MNZlCMpKDr8zKzGzJ4ws1fN7BUz+1rQ3tfM5prZsuB3n6DdzOwmM2sws4Vm\nNqbtMUih3n333axLKFt/+ctfWm0/5ZRTUq5E0hJlyW8H8A13PxQYB3zVzA4FLgcec/cRwGPBc4CT\ngBHBzwzglgjjllaMHDky6xLK1iGHHLJb25QpU3TBgwpWdPi5+yp3fyF4/B6wGBgMTANmBYPNAk4N\nHk8D7vacZ4HeZjao6MplN1ryi9cjjzySdQmSoFi2+ZnZUOBI4DlgoLuvCl56BxgYPB4MvJX3tsag\nTaRkzJw5M+sSJCWRw8/MegK/By5192YnlHpunaGg9QYzm2FmdWZWt3bt2qjlVZ2uXbtmXUJZu+GG\nG7IuQVISKfzMbG9ywXevuz8YNK8OV2eD32uC9pVATd7bhwRtzbj7re5e6+61AwYMiFJeVXr++eez\nLkGkLETZ22vAHcBid/9J3kuzgenB4+nAQ3ntXwj2+o4DNuWtHktE69evB2DUqFEZV1K+LrzwwqxL\nkBRFWfL7JHAecLyZ/TP4ORm4DphkZsuAicFzgD8DrwMNwG3ARRHGLS3069cv6xLK3vjx47MuQVLU\nudg3uvvTwJ7O/zmhleEd0HlXUrLmz5+fdQmSIp3hIRJ44oknsi5BUqTwqyDDhw/PuoSyFt7uU6qD\nwq+C3HnnnVmXIFI2FH4VZMKECVmXIFI2FH5VYPLkyVmXIFJyFH4V4I033mjz9alTp6ZUiUj5UPhV\ngOOPP77N188777yUKhEpHwq/CrB8+fI2X99nn33SKaTMff7zn8+6BEmRwk8k8JWvfCXrEiRFCr8K\n8bWvfS3rEsreMccck3UJkiKFX4XQpZhECqPwqxC6zaJIYRR+ZW7Lli17fO1vf/tbipWIlBeFX5kL\nb7HYmr///e8pViJSXhR+Za6tgFu0aFGKlYiUF4VfBVuyZEnWJYiULIVfBVu6dGnWJYiULIVfBfjV\nr37VavvmzZtbbZfWbd++PesSJEUKvwrwxS9+MesSKkJjY2PWJUiKFH5l7LLLLsu6hIoybNiwrEuQ\nFCn8ytj111+fdQkiZUvhJyJVSeEnIlVJ4Vfmbr/99qxLqDgPPfRQ1iVIChR+Ze7888/PuoSKo7vg\nVYfOWRcgydI16grj7lmXICnRkl+ZmjRpUoeGGz9+fMKViJQnhV+ZmjdvXoeG+8QnPpFwJSLlSeFX\nxoYMGdLuMCeccEIKlYiUn8jb/MysE1AHrHT3z5jZMOB+oB+wADjP3T8ws67A3cBYYB3wOXdfHnX8\nbRk1ahQvv/xykqPIVGNjY7MrOHfp0oXx48czceLEptXd3r17Z1WeSEmzqBt4zWwmUAvsG4Tfb4EH\n3f1+M/sF8JK732JmFwEfc/cLzOws4DR3/1xbfdfW1npdXV3Rte29997s2LGj6Pd3VK9evZg8eTKT\nJ0/mzDPPZMeOHcyfP5+5c+cyf/58nn322cRrSJp2BEipMLMF7l4buZ8oM7WZDQFmAf8HmAmcAqwF\n9nf3HWY2Hviuu082s0eDx/PNrDPwDjDA2yggavhVqqeffpoJEya0G0hm1u4w69atY8WKFSxdupTl\ny5ezYsUKlixZwooVK1i+fDm7du0CFH5SOuIKv6irvf8D/DcQ3hW7H7DR3cPFrUZgcPB4MPAWQBCM\nm4Lh383v0MxmADMADjzwwIjlVaYJEybE1le/fv3o168fY8aMia1PkXJQ9A4PM/sMsMbdF8RYD+5+\nq7vXunvtgAED4uxaRKRJlCW/TwJTzexkoBuwL3Aj0NvMOgdLf0OAlcHwK4EaoDFY7e1FbseHFKEj\ne3oled26dWPbtm3aLFCGil7yc/cr3H2Iuw8FzgIed/dzgSeA04PBpgPhiZKzg+cErz/e1vY+adtb\nb72VdQkCbN26NesSpEhJHOf3LWCmmTWQ26Z3R9B+B9AvaJ8JXJ7AuCWg21bmdvikdTN33TS+/MQS\nfu7+pLt/Jnj8ursf5e7D3f0Md98WtG8Nng8PXn89jnGXo3Xr1jF69OimD2f+z5o1a9p8b0c/ZLNn\nz46jVOmAu+++O+sSpAg6wyNFxx13HGZG//79eemll1odZuDAgbEsRTzxxBOR+5COOe+887IuIXWr\nVq0q+xMIFH4pCJfqnnrqKaZOnYq7t/kTvmfWrFmt9vevf/2r3XH+4x//iPVvKDf9+/cH4Kmnnkpt\nnNW06nvAAQcwatSoVDctxC3yGR5JKveDnPNniunTp3PXXXcV/N6W/5+OHLjc1vurRdp/fzVN7/y/\ntWXwpfH3x3WQs5b8EpI/U7h7QcEXvqdlP6eddlostZW7u+66q9XtpVkuhVTLDqaWIR+urTz33HNA\neV0IVkt+MWsZenH0d8stt3DBBRcUtHRRaUsirYVaTU0Nhx9+OB//+McZNWoUO3fu5Kyzzmo2TJp/\nv5kxderUir0MfnvzVFrzXFxLfu1uf8ryZ+zYsV5OAAd80aJFsffZ8nF7TjvttA4PW6rq6+ub/mbA\nu3Xr1uH3Aj5kyJAEq2t9nOU+zfekI3/bxRdfnMrfD9R5DPmiy9jHJOlvvc2bNxfU/4MPPli2G6Kh\n+ZJefX09H/3oRzv83nAapX0g+PDhw2loaEh1nGno6Ly93377pVFObLTNLwZJBt/o0aOB3GWzirF9\n+/Y4y0lc/na78Bu6kOAD2GuvbGbrSrh0WUvbtm0D4Bvf+Ea7wz722GNJlxMrhV9ESS/xffvb3470\n/j59+sRUSfLCafnQQw+V5bbKfv36ZV1C7Lp16wbAj3/843aHDXd6lAuFXwRpbOA944wzmh5v2rSp\n4Pd35JjArJ1zzjnNpuXUqVMzrqh9be1ZrrS98vPnz+/QcOV2nrPCr0gjRowA4L333kttnPvuu29B\nwxd6eE0WzIz77ruP/v37x7Z3PC17qvePf/xjajUkKZyW48aN69Dw4WaKcqHwK0JjYyMNDQ0cd9xx\n9OzZM+ty9mj69OntD5Sh8MO1dOlS1q5dm3E1HddWwP76179OsZLkhVfyrkQKvyLU1NQA5XP+7OrV\nq7MuYTd77703AH/605+alqIrwdlnnw0UvwTas2fPkjhoOxxvOR8x0B6FX4HSPng4jnNT586dG0Ml\n8ampqWHHjh1cccUVnHzyybH1m8YHNYn/f5cuXZqCLtxGe+ihhzYbZyWHUFYUfgXI4qyJ4447DoDO\nnSvjkMzVq1fT2NjIlClTuPbaa2Pvf/HixUDu6jhZ6ejhRbfffjtm1jR8/gG4r7zyStPjBx98EEhv\nKax79+5N9VQyhV8HPfnkk0B2M8Tpp5/e/kAlzt3Zf//9AXjkkUdi7TsMhkMOOQRIZlV/3rx5QPvz\nQPhFdcwxx+xxmJNOOokvf/nLTf211edpp53W6rneSdmyZUvi4ygFlbE4kYJPf/rTqY+z0lZ1woOP\ny3WJYtKkSQUN/8wzz7TafsABB7Bq1SoGDBjQ7sVr83lwFZWOXtknih/96EeJ9l8KtOTXAeEqVLl+\naEtBeLBsEtMwPPUvPBshCeEBzB2tf0/DbdiwgVWrVgEUFHyhZcuWFfyeYnzzm99MZTxZUvh1QDEz\naVwqJXC3bdvGokWLEuk7PPWvS5cuifQPsH79+qY91IX47Gc/2+x53759geL/r8OHDweSWyu4/vrr\nY+/znnvuKcmdNgq/dmR1aahwvGPHjgVg1KhRRfeV9WXWw7/l8MMPT2wcSV6xOaz/gw8+KPi9f/jD\nH3brp5S/0C677LJY++vRo0ez+S+r865bUzqVlLCTTjops3G/8MILQPRzfLPW0bMEChUGyrHHHtvU\nds0118Q+ngULFsTSTxw7rsI92kkJbwEQlZnx73//m8MOO6zZxU9LhS5m2oYtW7bQvXv3zJb6AJYs\nWcJHPvKRyH1l9X9Ocvwnn3wyjzzySKt9x7VTIEr97s5ee+3V7HLvcU2H8JjA8LCUuMQ13Y444ggW\nLlzYrC8z4/DDD4+8+UOXsU9B3DNWIcKZMErwAdx///0xVVS8pLbFtXe4TNQPcdTACt+f1NVezjnn\nnET6jcPChQsLas+Cwq/EhB+YuM6p/NznPhdLP1EksRe2I8GUf5ZEIWbOnBnrktr69esBeO211yL3\nla/UL5e/pyXyUqHw24PwnqRpri4uWbIk9XEm6Xe/+10i/d53330AzJkzp83h6uvrC+7bzLjhhhvo\n0aNHLP+H/B0IBx10UOT+khTXqYatBVwphV5I2/z2oE+fPmzcuDH1G+BA/OGXxkGxrWltu08cOjqd\nCp2e4fALFixgzJgxESqMVke599na/BZnvdrml7CNGzemOr5wu1gpfxkVKok9vIV8iJYuXQrA008/\n3eZwjz/+eLN+4wy+anPVVVft8bVSm7cVfiVgy5YtbN++vdnhGnHKaqY74YQTYu2v0KWHESNGMGnS\nJCZMmNDmfX7DOkvtw9mW6667LusSWvWDH/xgt7ZSXOWFiOFnZr3N7AEzqzezxWY23sz6mtlcM1sW\n/O4TDGtmdpOZNZjZQjPT12sg3Kuc5IG6WYhzyS/8ABV6Q6Y5c+bg7jzzzDMMGjSo1WHq6uoSDb6W\n9xKOw7e+9a3Y+4xLjx49dmtL4tjLqKIu+d0I/MXdDwGOABYDlwOPufsI4LHgOcBJwIjgZwZwS8Rx\nV4Ssj8NL0oEHHhhLP/nTqNhLex199NG8/fbbe7o/dCx1Vrsbb7wRgPfff7+pLfzftbU6nJWiw8/M\negHHAncAuPsH7r4RmAbMCgabBZwaPJ4G3B3cd/hZoLeZtf5VXAIuvPDCxMdRycGXL8q1CCtpGpXC\nMZdJuvTSS5s9nzlzJpD+9vOOirLkNwxYC/zKzF40s9vNrAcw0N1XBcO8A4RXlRwM5N9FujFoa8bM\nZphZnZnVZXlfh5///OcAXHTRRYn0H57vGF4nsJLt3Lmz4Pfs2rWrooIP/nOJ+ziV8vxzww03AMXf\nczppUcKvMzAGuMXdjwT+xX9WcQHw3Fxb0Jzr7re6e6271w4YMCBCefG45Zb4187NjHvuuYf58+fz\nqU99Kvb+S0kxF+E0Mzp16tTs/eXsqKOOSqzvSy65JLa+4pjW4cVky+GLK0r4NQKN7h7eqfgBcmG4\nOlydDX6H14NaCdTkvX9I0Fayop5a1ppwpvj617+e2Mn+paajAZh/2aOkd0KkafLkyYn1HR6MH6cp\nU6YU/d7nn3++LIIPIoSfu78DvGVmHw2aTgBeBWYD4T0TpwPhOTizgS8Ee33HAZvyVo9LUnjGRVy7\n6sN+XnvtNX7yk5/E0me5CE9xa+uQk1Cl7YQo9jS79kybNi2Rfh999NGi37vPPvsApR98EH1v7yXA\nvWa2EBgNXAtcB0wys2XAxOA5wJ+B14EG4DYgmY1pMYvj3gknnnhis2/DUj/NKQldunTZ470q9ttv\nv2Z7X6VjwpujFztvmhkbNmxo1hZO/zfffLOgvvIvs1Uu9/rV6W0d8PTTTzNhwgSg8G+0lks0Up1G\njhxJfX19Zqf6tfYegEGDBvH222+3+vr27ds7vKc+fM/mzZublv6SotPbUnTMMcdw7rnnArl/8siR\nI9t9T/6q3M6dOxV8VS6pC5CG89URRxzR5nDh3vNwnpw0aRLuvlvw5ffZkcv277///s3CNOngi5PC\nr4Puuece3J2hQ4dSX1/f5rarcGb44IMPmi5oKZLUF+CTTz7JwoULm+a90aNHs3jxYt54442mtvy9\n5+7e7hVx8jf3mFmzy5L99a9/bWpfvXp108Hs4T2my4VWe4t05JFH8s9//nO39q1bt9K1a9cMKpJq\nt6dtf+PGjWP+/PlF9Tlv3rw2b9mZH5JJXFm6NVrtzdiLL77Y6qlSCj7JSmvzo7sXHXwAEydOxN35\nzne+w9ChQ3nvvff2uHMqyyufF0NLfiISSf69StKgJT8RKQlnnHFG1iUUReEnIpH8/ve/z7qEoij8\nRKQqKfxEpCop/EQksi996UtZl1AwhZ+IRHbbbbdlXULBFH4iUpUUfiJStPDKMuVI4SciRbv33nuz\nLqFoCj8RKdoDDzyQdQlFU/iJSFVS+IlIVVL4iUhVUviJSFVS+IlIVVL4iUhVUviJSCRTp07NuoSi\nKPxEJJLa2sgXVc6Ewk9EIjn22GOzLqEoCj8RiWTs2LFZl1AUhZ+IRNKzZ8+sSyiKwk9EqpLCT0Sq\nUqTwM7Ovm9krZvaymd1nZt3MbJiZPWdmDWb2GzPrEgzbNXjeELw+NI4/QESkGEWHn5kNBv43UOvu\nhwOdgLOAHwI3uPtwYANwfvCW84ENQfsNwXAiIpmIutrbGfiQmXUGugOrgOOB8CJfs4BTg8fTgucE\nr59gZhZx/CIiRSk6/Nx9JfBj4E1yobcJWABsdPcdwWCNwODg8WDgreC9O4Lh+7Xs18xmmFmdmdWt\nXbu22PJERNoUZbW3D7mluWHAAUAPYErUgtz9VnevdffaAQMGRO1ORBKyffv2rEuIJMpq70TgDXdf\n6+7bgQeBTwK9g9VggCHAyuDxSqAGIHi9F7AuwvhFJEMbNmzIuoRIooTfm8A4M+sebLs7AXgVeAI4\nPRhmOvBQ8Hh28Jzg9cfd3SOMX0QytGbNmqxLiCTKNr/nyO24eAFYFPR1K/AtYKaZNZDbpndH8JY7\ngH5B+0zg8gh1i0jGNm7cmHUJkXRuf5A9c/ergatbNL8OHNXKsFuBM6KMT0RKRzWv9opIFSv3ozEU\nfiJSlPXr12ddQiQKPxEpisJPRCrGVVddhZkxceLEdod99913U6goOZF2eIhIZaitrWXBggVNz+fM\nmdPue8p9h4fCT6SKtTy9vpBDb9etK+9zFLTaK1KFzKwp+G6++WbcvaDgg/Lf26slP5EqE4Zer169\nIh2o/Nprr8VVUia05CdSJd55552m4HP3yGdobNmyJY6yMqPwE6kCc+bMYdCgQUBh2/UqmVZ7RSrc\npEmTmDdvHqDgy6fwE6lg4WrugQceyIoVKzKuprRotVekQu27774AHH300Qq+Vij8RCpQp06deO+9\n9zjvvPN45plnsi6nJCn8RCrMwIED2bVrFzfddBN333131uWULIWfSIUJr7B8ySWXZFxJaVP4iVQg\n7dVtn8JPpIKkfSvssWPHpjq+OCn8RCpEuLSX5lLfKaecktq44qbwE6kQe+2V/sd56tSpqY8zLgo/\nkQpy8cUXpzq+I488MtXxxUnhJ1IBwm19P/3pTzOupHwo/ESkKin8RCqEDm8pjMJPRKqSwk9EClZf\nX591CZEp/EQqRNQrMxdi9uzZqY0rKQo/kQpx5plnpjaua6+9NrVxJaXd8DOzO81sjZm9nNfW18zm\nmtmy4HefoN3M7CYzazCzhWY2Ju8904Phl5nZ9GT+HJHqNXfu3NTGtWnTptTGlZSOLPndBUxp0XY5\n8Ji7jwAeC54DnASMCH5mALdALiyBq4FPAEcBV4eBKSKShXbDz93/Cqxv0TwNmBU8ngWcmtd+t+c8\nC/Q2s0HAZGCuu6939w3AXHYPVBGR1BS7zW+gu68KHr8DDAweDwbeyhuuMWjbU7uIxGDVqtzHcdeu\nXamN8/rrr09tXEmIvMPDc0dWxnZ0pZnNMLM6M6sr9zvCi6Rl//33B3KXr0/LzJkzUxtXEooNv9XB\n6izB7zVB+0qgJm+4IUHbntp34+63unutu9cOGDCgyPJERNpWbPjNBsI9ttOBh/LavxDs9R0HbApW\njx8FTjSzPsGOjhODNhGJSXh6W2NjY6LjWbRoUaL9p6Xd+/aa2X3AcUB/M2skt9f2OuC3ZnY+sAII\nDzD6M3Ay0AD8G/gvAHdfb2bfB54PhrvG3VvuRBGRGNTU1CR6nu+pp57a/kBlwEr5ZOja2lqvq6vL\nugyRsmJmXH311Xz3u99NrH/I7kIKZrbA3Wuj9qMzPEQq0Pe+971E+y/lhaaOUviJVJgwmJK4mdGN\nN94Ye59ZUfiJVKAwAM8+++xY+7300ktj7S9LCj+RCtW3b1/uv//+2Pvt2rVr7H1mQeEnUqHWrVsH\nxLf6++qrrwKwdevWWPrLmsJPpILlb/+LeurbYYcdFkdJJUPhJ1LhwgDs1KkTr7/+elF93HbbbQDs\n3LkztrqypvATqQJhAB588MFFnQEyY8YMIJsboyelcv4SEWmTu9OlSxdqamowsw7f4Dzrg5qTovAT\nqSLbtm1rCrGbb765zZ0hffv2bXo9zUtlpaXdc3tFpPK4O++//z777LNPu3uDK22JL6QlP5Eq1bNn\nT9y96efKK69seu373/9+U3ul0oUNRKSs6MIGIiIRKPxEpCop/ESkKin8RKQqKfxEpCop/ESkKin8\nRKQqKfxEpCop/ESkKin8RKQqKfxEpCop/ESkKin8RKQqlfRVXczsPWBJ1nW0oj/wbtZFtKCaOqYU\na4LSrKtUa+rh7gOidlTqFzNdEsela+JmZnWlVpdq6phSrAlKs64SrmloHH1ptVdEqpLCT0SqUqmH\n361ZF7AHpViXauqYUqwJSrOuiq6ppHd4iIgkpdSX/EREEqHwE5GqVLLhZ2ZTzGyJmTWY2eUpjrfG\nzJ4ws1fN7BUz+1rQ3tfM5prZsuB3n6DdzOymoM6FZjYmwdo6mdmLZvZw8HyYmT0XjPs3ZtYlaO8a\nPG8IXh+aUD29zewBM6s3s8VmNr5EptPXg//dy2Z2n5l1S3tamdmdZrbGzF7Oayt42pjZ9GD4ZWY2\nPYGa/m/w/1toZn8ws955r10R1LTEzCbntcf62WytrrzXvmFmbmb9g+fxTav8+3aWyg/QCXgNOAjo\nArwEHJrSuAcBY4LH+wBLgUOBHwGXB+2XAz8MHp8MPAIYMA54LsHaZgK/Bh4Onv8WOCt4/AvgwuDx\nRcAvgsdnAb9JqJ5ZwJeCx12A3llPJ2Aw8Abwobxp9MW0pxVwLDAGeDmvraBpA/QFXg9+9wke94m5\nphOBzsHjH+bVdGjwuesKDAs+j52S+Gy2VlfQXgM8CqwA+sc9rRL5kMYw44wHHs17fgVwRUa1PARM\nInemyaCgbRC5A7ABfgmcnTd803Ax1zEEeAw4Hng4+Oe/mzfjNk2zYIYZHzzuHAxnMdfTKwgZa9Ge\n9XQaDLwVfAg6B9NqchbTChjaImgKmjbA2cAv89qbDRdHTS1eOw24N3jc7DMXTqekPput1QU8ABwB\nLOc/4RfbtCrV1d5wBg41Bm2pClaBjgSeAwa6+6rgpXeAgcHjtGr9H+C/gV3B837ARnff0cp4m2oK\nXt8UDB+nYcBa4FfBqvjtZtaDjKeTu68Efgy8Cawi97cvINtpFSp02qT9Ofhf5JaqMq/JzKYBK939\npRYvxVZXqYZf5sysJ/B74FJ335z/mue+WlI7RsjMPgOscfcFaY2zAzqTW1W5xd2PBP5FblWuSdrT\nCSDYjjaNXDgfAPQApqRZQ0dkMW3aYmZXAjuAe0uglu7At4HvJDmeUg2/leTW90NDgrZUmNne5ILv\nXnd/MGhebWaDgtcHAWtSrPWTwFQzWw7cT27V90agt5mF52fnj7eppuD1XsC6mGtqBBrd/bng+QPk\nwjDL6QQwEXjD3de6+3bgQXLTL8tpFSp02qQyzczsi8BngHODUM66poPJfXm9FMzzQ4AXzGz/OOsq\n1fB7HhgR7KHrQm5D9Ow0RmxmBtwBLHb3n+S9NBsI9yBNJ7ctMGz/QrAXahywKW/VJhbufoW7D/Hc\nCd1nAY+7+7nAE8Dpe6gprPX0YPhYlzLc/R3gLTP7aNB0AvAqGU6nwJvAODPrHvwvw7oym1Z5Cp02\njwInmlmfYIn2xKAtNmY2hdzmlKnu/u8WtZ4V7A0fBowA/kEKn013X+Tu+7n70GCebyS3E/Id4pxW\ncWzYTeKH3F6dpeT2LF2Z4niPIbc6shD4Z/BzMrntQI8By4B5QN9geANuDupcBNQmXN9x/Gdv70Hk\nZsgG4HdA16C9W/C8IXj9oIQxlUc8AAAAh0lEQVRqGQ3UBdPqj+T2smU+nYDvAfXAy8D/I7fHMtVp\nBdxHbpvj9uDDe34x04bcdriG4Oe/Eqipgdy2snBe/0Xe8FcGNS0BTsprj/Wz2VpdLV5fzn92eMQ2\nrXR6m4hUpVJd7RURSZTCT0SqksJPRKqSwk9EqpLCT0SqksJPRKqSwk9EqtL/B513b2Zu3yMeAAAA\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g09vae7pch_r",
        "outputId": "50a8ac0b-cd2b-4587-a07c-15996ad5d7a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_length = df['label'].astype(str).map(len).max()\n",
        "max_length"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uXoq7EfmpGFi"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9TCi2kBKbJ2K",
        "colab": {}
      },
      "source": [
        "# DenseNet: https://github.com/andreasveit/densenet-pytorch/blob/master/densenet.py\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, dropRate=0.0):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=1,\n",
        "                               padding=1, bias=False)\n",
        "        self.droprate = dropRate\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(self.relu(self.bn1(x)))\n",
        "        if self.droprate > 0:\n",
        "            out = F.dropout(out, p=self.droprate, training=self.training)\n",
        "        return torch.cat([x, out], 1)\n",
        "\n",
        "class BottleneckBlock(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, dropRate=0.0):\n",
        "        super(BottleneckBlock, self).__init__()\n",
        "        inter_planes = out_planes * 4\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv1 = nn.Conv2d(in_planes, inter_planes, kernel_size=1, stride=1,\n",
        "                               padding=0, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(inter_planes)\n",
        "        self.conv2 = nn.Conv2d(inter_planes, out_planes, kernel_size=3, stride=1,\n",
        "                               padding=1, bias=False)\n",
        "        self.droprate = dropRate\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(self.relu(self.bn1(x)))\n",
        "        if self.droprate > 0:\n",
        "            out = F.dropout(out, p=self.droprate, inplace=False, training=self.training)\n",
        "        out = self.conv2(self.relu(self.bn2(out)))\n",
        "        if self.droprate > 0:\n",
        "            out = F.dropout(out, p=self.droprate, inplace=False, training=self.training)\n",
        "        return torch.cat([x, out], 1)\n",
        "\n",
        "class TransitionBlock(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, dropRate=0.0):\n",
        "        super(TransitionBlock, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1,\n",
        "                               padding=0, bias=False)\n",
        "        self.droprate = dropRate\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(self.relu(self.bn1(x)))\n",
        "        if self.droprate > 0:\n",
        "            out = F.dropout(out, p=self.droprate, inplace=False, training=self.training)\n",
        "        return F.avg_pool2d(out, 2)\n",
        "\n",
        "class DenseBlock(nn.Module):\n",
        "    def __init__(self, nb_layers, in_planes, growth_rate, block, dropRate=0.0):\n",
        "        super(DenseBlock, self).__init__()\n",
        "        self.layer = self._make_layer(block, in_planes, growth_rate, nb_layers, dropRate)\n",
        "    def _make_layer(self, block, in_planes, growth_rate, nb_layers, dropRate):\n",
        "        layers = []\n",
        "        for i in range(nb_layers):\n",
        "            layers.append(block(in_planes+i*growth_rate, growth_rate, dropRate))\n",
        "        return nn.Sequential(*layers)\n",
        "    def forward(self, x):\n",
        "        return self.layer(x)\n",
        "\n",
        "class DenseNet(nn.Module):\n",
        "    def __init__(self, depth, growth_rate=12,\n",
        "                 reduction=0.5, bottleneck=True, dropRate=0.0):\n",
        "        super(DenseNet, self).__init__()\n",
        "        in_planes = 2 * growth_rate\n",
        "        n = (depth - 4) / 3\n",
        "        if bottleneck == True:\n",
        "            n = n/2\n",
        "            block = BottleneckBlock\n",
        "        else:\n",
        "            block = BasicBlock\n",
        "        n = int(n)\n",
        "        # 1st conv before any dense block\n",
        "        self.conv1 = nn.Conv2d(1, in_planes, kernel_size=3, stride=1,\n",
        "                               padding=1, bias=False)\n",
        "        # 1st block\n",
        "        self.block1 = DenseBlock(n, in_planes, growth_rate, block, dropRate)\n",
        "        in_planes = int(in_planes+n*growth_rate)\n",
        "        self.trans1 = TransitionBlock(in_planes, int(math.floor(in_planes*reduction)), dropRate=dropRate)\n",
        "        in_planes = int(math.floor(in_planes*reduction))\n",
        "        # 2nd block\n",
        "        self.block2 = DenseBlock(n, in_planes, growth_rate, block, dropRate)\n",
        "        in_planes = int(in_planes+n*growth_rate)\n",
        "        self.trans2 = TransitionBlock(in_planes, int(math.floor(in_planes*reduction)), dropRate=dropRate)\n",
        "        in_planes = int(math.floor(in_planes*reduction))\n",
        "        # 3rd block\n",
        "        self.block3 = DenseBlock(n, in_planes, growth_rate, block, dropRate)\n",
        "        in_planes = int(in_planes+n*growth_rate)\n",
        "        # global average pooling and classifier\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.in_planes = in_planes\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                m.bias.data.zero_()\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.trans1(self.block1(out))\n",
        "        out = self.trans2(self.block2(out))\n",
        "        out = self.block3(out)\n",
        "        out = self.relu(self.bn1(out))\n",
        "        # out = F.avg_pool2d(out, 8)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_DTOyLu7pRyb",
        "outputId": "0746d606-c28f-476b-93c1-0768c0287f6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "dense_growth_rate = 96\n",
        "dense_depth = 4\n",
        "densenet = DenseNet(dense_depth, dense_growth_rate)\n",
        "print(densenet)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DenseNet(\n",
            "  (conv1): Conv2d(1, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (block1): DenseBlock(\n",
            "    (layer): Sequential()\n",
            "  )\n",
            "  (trans1): TransitionBlock(\n",
            "    (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv1): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  )\n",
            "  (block2): DenseBlock(\n",
            "    (layer): Sequential()\n",
            "  )\n",
            "  (trans2): TransitionBlock(\n",
            "    (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  )\n",
            "  (block3): DenseBlock(\n",
            "    (layer): Sequential()\n",
            "  )\n",
            "  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7spxJryyyH-P",
        "colab": {}
      },
      "source": [
        "class Attention(nn.Module):\n",
        "  def __init__(self, encoder_dim, decoder_dim, attention_dim):\n",
        "    super(Attention, self).__init__()\n",
        "    self.encoder_att = nn.Linear(encoder_dim, attention_dim)\n",
        "    self.decoder_att = nn.Linear(decoder_dim, attention_dim)\n",
        "    self.attn = nn.Linear(attention_dim, 1)\n",
        "\n",
        "  def forward(self, decoder_hidden_state, encoder_outputs):\n",
        "    '''\n",
        "    encoder_outputs: [T, B, I]\n",
        "    decoder_hidden_state: [num_layers*num_directions, B, H] = [1, B, H]\n",
        "    '''\n",
        "    # pdb.set_trace()\n",
        "    att1 = self.encoder_att(encoder_outputs) # [T, B, A]\n",
        "    att2 = self.decoder_att(decoder_hidden_state) # [1, B, A]\n",
        "    att = self.attn(att1 + att2) # [T, B, 1]\n",
        "    att = att.squeeze(2) # [T, B]\n",
        "    \n",
        "    weights = F.softmax(att, dim=0) # [T, B]\n",
        "    \n",
        "    weights = weights.unsqueeze(2) # [T, B, 1]\n",
        "\n",
        "    context = weights * encoder_outputs\n",
        "\n",
        "    # context: [T, B, I]\n",
        "    # weights: [T, B, 1]\n",
        "    return context, weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YP9ghbN4pjIK",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    '''\n",
        "    Decode from previous character and current input\n",
        "    '''\n",
        "    def __init__(self, input_size, vocab_size, hidden_size, batch_size):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        self.rnn = nn.GRU(self.input_size + self.vocab_size, self.hidden_size)\n",
        "\n",
        "    def forward(self, prev_character, current_input, prev_hidden_state):\n",
        "        '''\n",
        "        prev_character: [1, B, V]\n",
        "        current_input:  [1, B, I]\n",
        "        prev_hidden_state: [num_layers*num_directions, B, H] = [1, B, H]\n",
        "        '''\n",
        "        rnn_input = torch.cat([current_input, prev_character], dim=-1) # [1, B, I+V]\n",
        "        return self.rnn(rnn_input, hidden_state)\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, self.batch_size, self.hidden_size).to(device)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1WVUfYYvzttX",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, batch_size, hidden_size, vocab_size, dense_growth_rate=96, dense_depth=4):\n",
        "        super(Model, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.encoder = DenseNet(dense_depth, dense_growth_rate)\n",
        "        self.input_size = self.encoder.in_planes\n",
        "\n",
        "        self.attn = Attention(self.input_size, hidden_size, hidden_size)\n",
        "        self.decoder = Decoder(self.input_size, vocab_size, hidden_size, batch_size)\n",
        "\n",
        "        self.final = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, batch_X, batch_Y, batch_Y_lengths):\n",
        "        '''\n",
        "        batch_X: [B, C, H, W]\n",
        "        batch_Y: [T, B, V]\n",
        "        batch_Y_lengths: [B, 1]\n",
        "        '''\n",
        "        pdb.set_trace()\n",
        "\n",
        "\n",
        "        # sort decrease by length of target batch_Y\n",
        "        sorted_lengths, sorted_idx = batch_Y_lengths.squeeze(1).sort(descending=True)\n",
        "        batch_X = batch_X[sorted_idx]\n",
        "        batch_Y = batch_Y[sorted_idx]\n",
        "\n",
        "\n",
        "        encoder_outputs = self.encoder(batch_X) # [B, C, H*W]\n",
        "        encoder_outputs = encoder_outputs.view(-1, self.batch_size, self.input_size) # [T, B, C], T = H*W\n",
        "\n",
        "        decoder_hidden = self.decoder.init_hidden()\n",
        "        decoder_outputs = []\n",
        "\n",
        "\n",
        "        for t in range(batch_Y.size(0)):\n",
        "            y_t = batch_Y[t].unsqueeze(0) # [1, B, V]\n",
        "            context, weights = self.attn(decoder_hidden, encoder_outputs)\n",
        "            # context: [T, B, I]\n",
        "            # weights: [T, B, 1]\n",
        "            decoder_output, decoder_hidden = self.decoder(y_t, context, decoder_hidden) # teacher forcing\n",
        "\n",
        "            decoder_output = self.final(decoder_output)\n",
        "            decoder_outputs.append(decoder_output)\n",
        "\n",
        "        predict_Y = torch.cat(decoder_outputs, dim=0)\n",
        "        return predict_Y # [T, B, V]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "k_3a2BJkqtWC"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wwIzyKrWch_8",
        "colab": {}
      },
      "source": [
        "def to_batch(samples):\n",
        "    batch_size = len(samples)\n",
        "\n",
        "    image_samples = [sample[0] for sample in samples]\n",
        "    label_samples = [sample[1] for sample in samples]\n",
        "\n",
        "    # batch_image: [B, C, H, W]\n",
        "    # image: [1, H, W] - grayscale\n",
        "    max_image_row = max([image.shape[1] for image in image_samples])\n",
        "    max_image_col = max([image.shape[2] for image in image_samples])\n",
        "    batch_image = torch.ones(batch_size, 1, max_image_row, max_image_col)\n",
        "    for i, image in enumerate(image_samples):\n",
        "      image_row = image.shape[1]\n",
        "      image_col = image.shape[2]\n",
        "      batch_image[i, 0, :image_row, :image_col] = image\n",
        "\n",
        "    # batch_label: [T, B, V]\n",
        "    batch_label_lengths = np.array([len(label) for label in label_samples])\n",
        "    max_label_lengths = batch_label_lengths.max()\n",
        "    \n",
        "    batch_label_lengths = torch.from_numpy(batch_label_lengths).unsqueeze(-1) # [B, 1]\n",
        "    vocab_size = label_samples[0].shape[1]\n",
        "\n",
        "    batch_label = np.zeros((batch_size, max_label_lengths, vocab_size)) # [B, T, V]\n",
        "    # pdb.set_trace()\n",
        "    for i, label in enumerate(label_samples):\n",
        "      batch_label[i, :label.shape[0]] = label\n",
        "    batch_label = torch.from_numpy(batch_label) # [B, T, V]\n",
        "\n",
        "    # sort by decreasing lengths\n",
        "    batch_label_lengths, sorted_idx = batch_label_lengths.squeeze(-1).sort(descending=True)\n",
        "    batch_image = batch_image[sorted_idx]\n",
        "    batch_label = batch_label[sorted_idx].transpose(0, 1) # [T, B, V]\n",
        "\n",
        "    return batch_image, batch_label, batch_label_lengths"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "spMDvL8rq2IC",
        "colab": {}
      },
      "source": [
        "batch_size = 8\n",
        "input_size = 9600 # temp\n",
        "hidden_size = 256\n",
        "seq_lens = 256 # TODO: = max len of all sequencs in dataset\n",
        "vocab_size = len(label_encoder_decoder.alphabets)\n",
        "\n",
        "learning_rate = 0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J-wLzwHmch_9",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(dataset, batch_size=batch_size, collate_fn=to_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bBs1FzlQciAA",
        "colab": {}
      },
      "source": [
        "loader_iter = iter(train_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YqjZkG-9ciAE",
        "outputId": "743b3fcc-7247-4314-8797-4b24ab8a0cf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%time\n",
        "batch_X, batch_y, batch_y_lengths = next(loader_iter)\n",
        "# print(batch_X.shape, batch_y.shape, batch_y_lengths.shape)"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
            "Wall time: 9.3 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGGMbY82PuxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_y_lengths"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sydp7s9H8Q3Z",
        "colab": {}
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VaqnWXuwwjgu",
        "colab": {}
      },
      "source": [
        "model = Model(\n",
        "    batch_size,\n",
        "    hidden_size,\n",
        "    vocab_size,\n",
        "    dense_growth_rate,\n",
        "    dense_depth\n",
        ")\n",
        "\n",
        "# model.train() # set mode to train\n",
        "model = model.to(device)\n",
        "x_train = batch_X.to(device)\n",
        "y_train = batch_y.to(device)\n",
        "y_lengths = batch_y_lengths"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfDzwORzE1ve",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "64a0cf5f-e0b7-452b-f813-2aacc4f17711"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 8, 216])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pbiUwu_YGH8w",
        "outputId": "08532a6c-2cff-4fb3-d97a-77304524bcf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "predict_Y = model(x_train, y_train, y_lengths)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-48487e5eb90f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-2e26fc4733bf>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch_X, batch_Y, batch_Y_lengths)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mencoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [B, C, H*W]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mencoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [T, B, C], T = H*W\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-3cadf7ccf57b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrans1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrans2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_d0TXajA7Rt9",
        "colab": {}
      },
      "source": [
        "predict_Y.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUD9X44j-4hZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = torch.rand(1, 3, 2)\n",
        "b = torch.rand(1, 3, 3)\n",
        "c = torch.cat([a, b], dim=-1)\n",
        "c.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_2NiB4FDcML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}