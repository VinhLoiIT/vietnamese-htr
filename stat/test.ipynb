{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import unicodedata\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flattening(object):\n",
    "    def __init__(self):\n",
    "        self.accent2unicode = {'<6>': '\\u0302', '<8>': '\\u0306', '<F>': '\\u0300', \\\n",
    "                               '<S>': '\\u0301', '<R>': '\\u0309', '<X>': '\\u0303', '<J>': '\\u0323'}\n",
    "        self.circumflex_unicodes = ['00C2', '00E2', '00CA', '00EA', '00D4', '00F4'] # â, Â, Ê, ...\n",
    "        self.breve_unicodes = ['0102', '0103'] # ă, Ă\n",
    "        self.underdot_unicodes = ['1EA0', '1EA1', '1EB8', '1EB9', '1ECC', '1ECD']\n",
    "        self.accent_letters = 'À Á Ả Ã Ạ Â Ầ Ấ Ẩ Ẫ Ậ Ă Ằ Ắ Ẳ Ẵ Ặ à á ả ã ạ â ầ ấ ẩ ẫ ậ ă ằ ắ ẳ ẵ ặ\\\n",
    "        È É Ẻ Ẽ Ẹ Ê Ề Ế Ể Ễ Ệ è é ẻ ẽ ẹ ê ề ế ể ễ ệ\\\n",
    "        Ì Í Ỉ Ĩ Ị ì í ỉ ĩ ị\\\n",
    "        Ò Ó Ỏ Õ Ọ Ô Ồ Ố Ổ Ỗ Ộ Ơ Ờ Ớ Ở Ỡ Ợ ò ó ỏ õ ọ ô ồ ố ổ ỗ ộ ơ ờ ớ ở ỡ ợ\\\n",
    "        Ù Ú Ủ Ũ Ụ Ư Ừ Ứ Ử Ữ Ự ù ú ủ ũ ụ ư ừ ứ ử ữ ự\\\n",
    "        Ỳ Ý Ỷ Ỹ Ỵ ỳ ý ỷ ỹ ỵ'\n",
    "        self.accent_letters = self.accent_letters.split()\n",
    "        \n",
    "    def get_unaccent(self, letter):\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def get_accents(self, letter):\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def flatten_letter(self, letter):\n",
    "        flattened_letter = []\n",
    "        if letter not in self.accent_letters:\n",
    "            return letter\n",
    "        unaccent_letter = self.get_unaccent(letter)\n",
    "        mark_accent, vowel_accent = self.get_accents(letter)\n",
    "        flattened_letter.append(unaccent_letter)\n",
    "        if mark_accent != None:\n",
    "            flattened_letter.append(mark_accent)\n",
    "        if vowel_accent != None:\n",
    "            flattened_letter.append(vowel_accent)\n",
    "        return flattened_letter\n",
    "    \n",
    "    '''\n",
    "    Types:\n",
    "    ------\n",
    "        - word: list of accent-letters\n",
    "        Return:\n",
    "        - flattened_word: list of unaccent-letters [and <accent-letters> (if any)]\n",
    "    '''\n",
    "    def flatten_word(self, word):\n",
    "        flattened_word = []\n",
    "        for letter in word:\n",
    "            flattened_letter = self.flatten_letter(letter)\n",
    "            flattened_word.extend(flattened_letter)\n",
    "        return flattened_word\n",
    "    \n",
    "    def invert(self, flattened_word):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Flatten without đ, Đ, ơ, Ơ, ư, Ư\n",
    "'''\n",
    "class Flattening_1(Flattening):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def get_unaccent(self, letter):\n",
    "        letter = letter.encode('utf-8').decode('utf-8')\n",
    "        letter = re.sub(u'[àáảãạâầấẩẫậăằắẳẵặ]', 'a', letter)\n",
    "        letter = re.sub(u'[ÀÁẢÃẠÂẦẤẨẪẬĂẰẮẲẴẶ]', 'A', letter)\n",
    "        letter = re.sub(u'[èéẹẻẽêềếệểễ]', 'e', letter)\n",
    "        letter = re.sub(u'[ÈÉẸẺẼÊỀẾỆỂỄ]', 'E', letter)\n",
    "        letter = re.sub(u'[òóọỏõôồốộổỗ]', 'o', letter)\n",
    "        letter = re.sub(u'[ÒÓỌỎÕÔỒỐỘỔỖ]', 'O', letter)\n",
    "        letter = re.sub(u'[ơờớợởỡ]', 'ơ', letter)\n",
    "        letter = re.sub(u'[ƠỜỚỢỞỠ]', 'Ơ', letter)\n",
    "        letter = re.sub(u'[ìíịỉĩ]', 'i', letter)\n",
    "        letter = re.sub(u'[ÌÍỊỈĨ]', 'I', letter)\n",
    "        letter = re.sub(u'[ùúụủũ]', 'u', letter)\n",
    "        letter = re.sub(u'[ÙÚỤỦŨ]', 'U', letter)\n",
    "        letter = re.sub(u'[ưừứựửữ]', 'ư', letter)\n",
    "        letter = re.sub(u'[ƯỪỨỰỬỮ]', 'Ư', letter)\n",
    "        letter = re.sub(u'[ỳýỵỷỹ]', 'y', letter)\n",
    "        letter = re.sub(u'[ỲÝỴỶỸ]', 'Y', letter)\n",
    "        return letter\n",
    "        \n",
    "    def get_accents(self, letter):\n",
    "        mark_accent, vowel_accent = None, None\n",
    "        bi_unicode = unicodedata.decomposition(letter).split()\n",
    "\n",
    "        if bi_unicode[1]=='0302' or (bi_unicode[0] in self.circumflex_unicodes) or letter=='ậ' or letter=='Ậ':\n",
    "            mark_accent = '<6>' # VNI '<CIRCUMFLEX>'\n",
    "        elif bi_unicode[1]=='0306' or (bi_unicode[0] in self.breve_unicodes) or letter=='ặ' or letter=='Ặ':\n",
    "            mark_accent = '<8>' # '<BREVE>'\n",
    "            \n",
    "        if bi_unicode[1]=='0300':\n",
    "            vowel_accent = '<F>'\n",
    "        elif bi_unicode[1]=='0301':\n",
    "            vowel_accent = '<S>'\n",
    "        elif bi_unicode[1]=='0303':\n",
    "            vowel_accent = '<X>'\n",
    "        elif bi_unicode[1]=='0309':\n",
    "            vowel_accent = '<R>'\n",
    "        elif bi_unicode[1]=='0323' or (bi_unicode[0] in self.underdot_unicodes):\n",
    "            vowel_accent = '<J>'\n",
    "\n",
    "        return mark_accent, vowel_accent\n",
    "    \n",
    "    '''\n",
    "    Types:\n",
    "    ------\n",
    "        - flattened_word: list of unaccent-letters [and <accent-letters> (if any)]\n",
    "        Return:\n",
    "        - accent_word: list of accent-letters\n",
    "    '''\n",
    "    def invert(self, flattened_word):\n",
    "        accent_word = []\n",
    "        for letter in flattened_word:\n",
    "            if (len(letter) == 1) or (len(accent_word) == 0) or (letter not in self.accent2unicode):\n",
    "                accent_word.append(letter)\n",
    "            else: # accent\n",
    "                accent_letter = unicodedata.normalize('NFC', accent_word[-1] + self.accent2unicode[letter])\n",
    "                accent_word[-1] = accent_letter\n",
    "        return accent_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Flatten with đ, Đ, ơ, Ơ, ư, Ư\n",
    "'''\n",
    "class Flattening_2(Flattening):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "#         self.accent2unicode['<7>'] = '\\u031B'\n",
    "        self.accent2unicode.update({'<7>': '\\u031B', '<9>': None})\n",
    "        self._7_unicodes = ['01A0', '01A1', '01AF', '01B0']\n",
    "        self.accent_letters.extend(['đ', 'Đ'])\n",
    "        \n",
    "    def get_unaccent(self, letter):\n",
    "        letter = letter.encode('utf-8').decode('utf-8')\n",
    "        letter = re.sub(u'đ', 'd', letter)\n",
    "        letter = re.sub(u'Đ', 'D', letter)\n",
    "        return ''.join(c for c in unicodedata.normalize('NFD', letter)\\\n",
    "                       if unicodedata.category(c) != 'Mn')\n",
    "        \n",
    "    def get_accents(self, letter):\n",
    "        mark_accent, vowel_accent = None, None\n",
    "        bi_unicode = unicodedata.decomposition(letter).split()\n",
    "\n",
    "        if letter=='đ' or letter=='Đ':\n",
    "            mark_accent = '<9>'\n",
    "        elif bi_unicode[1]=='0302' or (bi_unicode[0] in self.circumflex_unicodes) or letter=='ậ' or letter=='Ậ':\n",
    "            mark_accent = '<6>' # VNI '<CIRCUMFLEX>'\n",
    "        elif bi_unicode[1]=='0306' or (bi_unicode[0] in self.breve_unicodes) or letter=='ặ' or letter=='Ặ':\n",
    "            mark_accent = '<8>' # '<BREVE>'\n",
    "        elif bi_unicode[1]=='031B' or (bi_unicode[0] in self._7_unicodes):\n",
    "            mark_accent = '<7>'\n",
    "            \n",
    "        if letter=='đ' or letter=='Đ':\n",
    "            vowel_accent = None\n",
    "        elif bi_unicode[1]=='0300':\n",
    "            vowel_accent = '<F>'\n",
    "        elif bi_unicode[1]=='0301':\n",
    "            vowel_accent = '<S>'\n",
    "        elif bi_unicode[1]=='0303':\n",
    "            vowel_accent = '<X>'\n",
    "        elif bi_unicode[1]=='0309':\n",
    "            vowel_accent = '<R>'\n",
    "        elif bi_unicode[1]=='0323' or (bi_unicode[0] in self.underdot_unicodes):\n",
    "            vowel_accent = '<J>'\n",
    "\n",
    "        return mark_accent, vowel_accent\n",
    "    \n",
    "    '''\n",
    "    Types:\n",
    "    ------\n",
    "        - flattened_word: list of unaccent-letters [and <accent-letters> (if any)]\n",
    "        Return:\n",
    "        - accent_word: list of accent-letters\n",
    "    '''\n",
    "    def invert(self, flattened_word):\n",
    "        accent_word = []\n",
    "        for letter in flattened_word:\n",
    "            if (len(letter) == 1) or (len(accent_word) == 0) or (letter not in self.accent2unicode):\n",
    "                accent_word.append(letter)\n",
    "            else: # accent\n",
    "                if letter == '<9>':\n",
    "                    if accent_word[-1] in ['d', 'D']:\n",
    "                        accent_letter = ('đ' if accent_word[-1]=='d' else 'Đ')\n",
    "                        accent_word[-1] = accent_letter\n",
    "                    else:\n",
    "                        accent_word.append(letter)\n",
    "                else:\n",
    "                    accent_letter = unicodedata.normalize('NFC', accent_word[-1] + self.accent2unicode[letter])\n",
    "                    accent_word[-1] = accent_letter\n",
    "        return accent_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# type_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quý        - ['q', 'u', 'y', '<S>']                   - ['q', 'u', 'ý']\n",
      "hóa        - ['h', 'o', '<S>', 'a']                   - ['h', 'ó', 'a']\n",
      "hoàn       - ['h', 'o', 'a', '<F>', 'n']              - ['h', 'o', 'à', 'n']\n",
      "khoáng     - ['k', 'h', 'o', 'a', '<S>', 'n', 'g']    - ['k', 'h', 'o', 'á', 'n', 'g']\n",
      "gì         - ['g', 'i', '<F>']                        - ['g', 'ì']\n",
      "gìn        - ['g', 'i', '<F>', 'n']                   - ['g', 'ì', 'n']\n",
      "đoán       - ['đ', 'o', 'a', '<S>', 'n']              - ['đ', 'o', 'á', 'n']\n",
      "đứng       - ['đ', 'ư', '<S>', 'n', 'g']              - ['đ', 'ứ', 'n', 'g']\n",
      "lặng       - ['l', 'a', '<8>', '<J>', 'n', 'g']       - ['l', 'ặ', 'n', 'g']\n",
      "HĐND       - ['H', 'Đ', 'N', 'D']                     - ['H', 'Đ', 'N', 'D']\n",
      "ơn         - ['ơ', 'n']                               - ['ơ', 'n']\n",
      "\n",
      "['h', 'o', '<start>', 'a']\n",
      "['<9>', 'a', 'n']\n",
      "['q', '<9>', 'a', 'n']\n"
     ]
    }
   ],
   "source": [
    "flattening = Flattening_1()\n",
    "\n",
    "string1 = 'quý hóa hoàn khoáng gì gìn đoán đứng lặng HĐND ơn'\n",
    "for word in string1.split():\n",
    "    word = re.findall(r'\\w+', word)[0]\n",
    "    l_word = list(word)\n",
    "    flattened_word = flattening.flatten_word(l_word)\n",
    "    accent_word = flattening.invert(flattened_word)\n",
    "    print(f'{word: <{10}} - {str(flattened_word): <{40}} - {str(accent_word)}')\n",
    "    \n",
    "# Special case\n",
    "print()\n",
    "s_cases = [['h', 'o', '<start>', 'a'], ['<9>', 'a', 'n'], ['q', '<9>', 'a', 'n']]\n",
    "for case in s_cases:\n",
    "    print(flattening.invert(case))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/VNOnDB/all_word.csv', sep='\\t')\n",
    "ground_truth = df.loc[:, 'label'].astype(str)\n",
    "accent_words = []\n",
    "for word in ground_truth:\n",
    "    l_word = list(word)\n",
    "    l_flattened_word = flattening.flatten_word(l_word)\n",
    "    l_accent_word = flattening.invert(l_flattened_word)\n",
    "    accent_word = ''.join(l_accent_word)\n",
    "    accent_words.append(accent_word)\n",
    "    if word!=accent_word:\n",
    "        print(word, '-', accent_word)\n",
    "sum(ground_truth==accent_words)==len(ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# type_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quý        - ['q', 'u', 'y', '<S>']                   - ['q', 'u', 'ý']\n",
      "hóa        - ['h', 'o', '<S>', 'a']                   - ['h', 'ó', 'a']\n",
      "hoàn       - ['h', 'o', 'a', '<F>', 'n']              - ['h', 'o', 'à', 'n']\n",
      "khoáng     - ['k', 'h', 'o', 'a', '<S>', 'n', 'g']    - ['k', 'h', 'o', 'á', 'n', 'g']\n",
      "gì         - ['g', 'i', '<F>']                        - ['g', 'ì']\n",
      "gìn        - ['g', 'i', '<F>', 'n']                   - ['g', 'ì', 'n']\n",
      "đoán       - ['d', '<9>', 'o', 'a', '<S>', 'n']       - ['đ', 'o', 'á', 'n']\n",
      "đứng       - ['d', '<9>', 'u', '<7>', '<S>', 'n', 'g'] - ['đ', 'ứ', 'n', 'g']\n",
      "lặng       - ['l', 'a', '<8>', '<J>', 'n', 'g']       - ['l', 'ặ', 'n', 'g']\n",
      "HĐND       - ['H', 'D', '<9>', 'N', 'D']              - ['H', 'Đ', 'N', 'D']\n",
      "ơn         - ['o', '<7>', 'n']                        - ['ơ', 'n']\n",
      "\n",
      "['h', 'o', '<start>', 'a']\n",
      "['<9>', 'a', 'n']\n",
      "['q', '<9>', 'a', 'n']\n"
     ]
    }
   ],
   "source": [
    "flattening = Flattening_2()\n",
    "\n",
    "string1 = 'quý hóa hoàn khoáng gì gìn đoán đứng lặng HĐND ơn'\n",
    "for word in string1.split():\n",
    "    word = re.findall(r'\\w+', word)[0]\n",
    "    l_word = list(word)\n",
    "    flattened_word = flattening.flatten_word(l_word)\n",
    "    accent_word = flattening.invert(flattened_word)\n",
    "    print(f'{word: <{10}} - {str(flattened_word): <{40}} - {str(accent_word)}')\n",
    "    \n",
    "# Special case\n",
    "print()\n",
    "s_cases = [['h', 'o', '<start>', 'a'], ['<9>', 'a', 'n'], ['q', '<9>', 'a', 'n']]\n",
    "for case in s_cases:\n",
    "    print(flattening.invert(case))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/VNOnDB/all_word.csv', sep='\\t')\n",
    "ground_truth = df.loc[:, 'label'].astype(str)\n",
    "accent_words = []\n",
    "for word in ground_truth:\n",
    "    l_word = list(word)\n",
    "    l_flattened_word = flattening.flatten_word(l_word)\n",
    "    l_accent_word = flattening.invert(l_flattened_word)\n",
    "    accent_word = ''.join(l_accent_word)\n",
    "    accent_words.append(accent_word)\n",
    "    if word!=accent_word:\n",
    "        print(word, '-', accent_word)\n",
    "sum(ground_truth==accent_words)==len(ground_truth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
