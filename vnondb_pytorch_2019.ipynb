{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RdyIpXsB0yUE"
   },
   "source": [
    "# Load dataset from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "LcR8wysPjzOB",
    "outputId": "4418fc8a-0c77-49d7-80ad-725dd8125931"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S_zVf9zReBXA"
   },
   "outputs": [],
   "source": [
    "!mkdir -p ./data/VNOnDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "IDyCPQ16gb3v",
    "outputId": "5b6add74-f734-4fd3-e7ae-f58e95a31b37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace ./data/VNOnDB/word_train/20140927_0017_6046_1_tg_4_4_1.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
      "N\n",
      "N\n",
      "Extracted word_train.zip\n"
     ]
    }
   ],
   "source": [
    "!unzip './drive/My Drive/VNOnDB/word_train.zip' -d ./data/VNOnDB >> log_extract.txt\n",
    "print('Extracted word_train.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ApuJX1-AftE3",
    "outputId": "438a2862-dc33-44cd-c9e0-baea9ad294e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace ./data/VNOnDB/word_val/20151224_0141_7818_1_tg_0_0_0.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
      "Extracted word_val.zip\n"
     ]
    }
   ],
   "source": [
    "!unzip './drive/My Drive/VNOnDB/word_val.zip' -d ./data/VNOnDB >> log_extract.txt\n",
    "print('Extracted word_val.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "VogoOFvTfMg_",
    "outputId": "8940552b-aa37-4cae-cbb0-b3736dca366e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace ./data/VNOnDB/word_test/20151208_0146_7105_1_tg_0_0_0.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
      "Extracted word_test.zip\n"
     ]
    }
   ],
   "source": [
    "!unzip './drive/My Drive/VNOnDB/word_test.zip' -d ./data/VNOnDB >> log_extract.txt\n",
    "print('Extracted word_test.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "etUi9fPsgp1x",
    "outputId": "f3f9231a-2768-4ef0-cdbf-492b5520ada0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied csv files\n"
     ]
    }
   ],
   "source": [
    "!cp './drive/My Drive/VNOnDB/train_word.csv' ./data/VNOnDB/\n",
    "!cp './drive/My Drive/VNOnDB/test_word.csv' ./data/VNOnDB/\n",
    "!cp './drive/My Drive/VNOnDB/validation_word.csv' ./data/VNOnDB/\n",
    "print('Copied csv files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p7be0t5-ch_X"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "\n",
    "from utils import encode, decode, eos_char, alphabets, to_one_hot\n",
    "from dataset import VNOnDB\n",
    "from model import Model\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uh_VdlXsch_c"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "from Levenshtein import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yYixKHSGch_m"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k_3a2BJkqtWC"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-_2NiB4FDcML"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "hidden_size = 256\n",
    "vocab_size = len(alphabets)\n",
    "learning_rate = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    batch_size,\n",
    "    hidden_size,\n",
    "    vocab_size,\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = './data/VNOnDB/word_train/'\n",
    "val_folder = './data/VNOnDB/word_val/'\n",
    "test_folder = './data/VNOnDB/word_test/'\n",
    "\n",
    "train_df = pd.read_csv(f'./data/VNOnDB/train_word.csv', sep='\\t', index_col=0)\n",
    "val_df = pd.read_csv(f'./data/VNOnDB/validation_word.csv', sep='\\t', index_col=0)\n",
    "test_df = pd.read_csv(f'./data/VNOnDB/test_word.csv', sep='\\t', index_col=0)\n",
    "\n",
    "train_dataset = VNOnDB(f'./data/VNOnDB/word_train', train_df, image_transform, label_transform)\n",
    "val_dataset = VNOnDB(f'./data/VNOnDB/word_val', val_df, image_transform, label_transform)\n",
    "test_dataset = VNOnDB(f'./data/VNOnDB/word_test', test_df, image_transform, label_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=to_batch)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True, collate_fn=to_batch)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=True, collate_fn=to_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './model_ckpt'\n",
    "if not os.path.exists(model_path):\n",
    "    os.mkdir(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(epoch, model, optimizer, is_best):\n",
    "    state = {'epoch': epoch,\n",
    "             'model': model.state_dict(),\n",
    "             'optimizer': optimizer}\n",
    "    filename = 'checkpoint_' + str(epoch) + '.pth.tar'\n",
    "    filepath = os.path.join(model_path, filename)\n",
    "    torch.save(state, filepath)\n",
    "    # If this checkpoint is the best so far, store a copy so it doesn't get overwritten by a worse checkpoint\n",
    "    if is_best:\n",
    "        torch.save(state, os.path.join(model_path, 'BEST_' + filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, data_loader):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels, labels_one_hot, label_lengths) in enumerate(data_loader):\n",
    "            inputs = inputs.type(float_dtype).to(device)\n",
    "            labels_one_hot = labels_one_hot.type(float_dtype).to(device)\n",
    "            labels = labels.type(long_dtype).to(device)\n",
    "            label_lengths = label_lengths.type(long_dtype).to(device)\n",
    "            \n",
    "            outputs = model(inputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-23-df708ed4544b>(13)<module>()\n",
      "-> inputs = inputs.type(float_dtype).to(device) # [B, 3, H, W]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-23-df708ed4544b>(14)<module>()\n",
      "-> labels_one_hot = labels_one_hot.type(float_dtype).to(device) # [T, B, V]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-23-df708ed4544b>(15)<module>()\n",
      "-> labels = labels.type(long_dtype).to(device) # [T, B, 1]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-23-df708ed4544b>(16)<module>()\n",
      "-> label_lengths = label_lengths.type(long_dtype).to(device) # [B, 1]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-23-df708ed4544b>(18)<module>()\n",
      "-> packed_labels = nn.utils.rnn.pack_padded_sequence(labels_one_hot, label_lengths)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-23-df708ed4544b>(20)<module>()\n",
      "-> optimizer.zero_grad()\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  packed_labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PackedSequence(data=tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]]), batch_sizes=tensor([8, 8, 8, 4, 1]), sorted_indices=None, unsorted_indices=None)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-23-df708ed4544b>(23)<module>()\n",
      "-> packed_outputs = model(inputs, packed_labels, label_lengths) # [T, B, V]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttributeError: 'PackedSequence' object has no attribute 'size'\n",
      "> <ipython-input-23-df708ed4544b>(23)<module>()\n",
      "-> packed_outputs = model(inputs, packed_labels, label_lengths) # [T, B, V]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "float_dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "long_dtype = torch.cuda.LongTensor if device == 'cuda' else torch.LongTensor\n",
    "\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels, labels_one_hot, label_lengths) in enumerate(train_loader):\n",
    "        pdb.set_trace()\n",
    "        inputs = inputs.type(float_dtype).to(device) # [B, 3, H, W]\n",
    "        labels_one_hot = labels_one_hot.type(float_dtype).to(device) # [T, B, V]\n",
    "        labels = labels.type(long_dtype).to(device) # [T, B, 1]\n",
    "        label_lengths = label_lengths.type(long_dtype).to(device) # [B, 1]\n",
    "        \n",
    "        packed_labels = nn.utils.rnn.pack_padded_sequence(labels_one_hot, label_lengths)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        packed_outputs = model(inputs, packed_labels, label_lengths) # [T, B, V]\n",
    "        outputs, input_sizes = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
    "        \n",
    "        outputs = outputs.reshape(-1, vocab_size) # [T*B, V]\n",
    "        labels = labels.reshape(-1) # [T*B*1]\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "904 - 689"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eos_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'pytorch-tutorial'...\n",
      "remote: Enumerating objects: 816, done.\u001b[K\n",
      "remote: Total 816 (delta 0), reused 0 (delta 0), pack-reused 816\u001b[K\n",
      "Receiving objects: 100% (816/816), 12.78 MiB | 4.24 MiB/s, done.\n",
      "Resolving deltas: 100% (432/432), done.\n",
      "Checking connectivity... done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/yunjey/pytorch-tutorial"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Copy of gated_attention.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}